{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "i1JlUA_e44zk",
        "Way0JYuMnSe1",
        "PYSxM81Hne5Q",
        "BtUBKyZMnr6n",
        "XOgDKoVwnusG",
        "Qc8sfcWqnwih",
        "MuG2FP4o1Kd6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Midhat/CUDA/blob/main/alimidhat_GPU_Practical2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ali Midhat Abdelgadir Abdalla**"
      ],
      "metadata": {
        "id": "8iEEg2_IsQSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 2**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify with the instruction below the details of the GPU which is available to you.  "
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "492b8ebf-b0b5-462a-852f-1c39ca1efc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb  8 17:40:02 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "First we upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "c09409f7-4b69-4797-c807-541079b6c9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 17:40:02--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K   133KB/s    in 0.2s    \n",
            "\n",
            "2025-02-08 17:40:04 (133 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2025-02-08 17:40:04--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-08 17:40:05 (355 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file prac2.cu."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(4)"
      ],
      "metadata": {
        "id": "Way0JYuMnSe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Version 1"
      ],
      "metadata": {
        "id": "7eQYYevPJabm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2.cu\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__constant__ int   N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "__global__ void pathcalc(float *d_z, float *d_v)\n",
        "{\n",
        "  float s1, s2, y1, y2, payoff;\n",
        "  int   ind;\n",
        "\n",
        "  // move array pointers to correct position\n",
        "\n",
        "  // version 1\n",
        "  ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "  // version 2\n",
        "  // ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "\n",
        "  // path calculation\n",
        "\n",
        "  s1 = 1.0f;\n",
        "  s2 = 1.0f;\n",
        "\n",
        "  for (int n=0; n<N; n++) {\n",
        "    y1   = d_z[ind];\n",
        "    // version 1\n",
        "    ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    // ind += 1;\n",
        "\n",
        "    y2   = rho*y1 + alpha*d_z[ind];\n",
        "    // version 1\n",
        "    ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    // ind += 1;\n",
        "\n",
        "    s1 = s1*(con1 + con2*y1);\n",
        "    s2 = s2*(con1 + con2*y2);\n",
        "  }\n",
        "\n",
        "  // put payoff value into device array\n",
        "\n",
        "  payoff = 0.0f;\n",
        "  if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n",
        "\n",
        "  d_v[threadIdx.x + blockIdx.x*blockDim.x] = payoff;\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int     NPATH=9600000, h_N=100;\n",
        "  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "  float  *h_v, *d_v, *d_z;\n",
        "  double  sum1, sum2;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory on host and device\n",
        "\n",
        "  h_v = (float *)malloc(sizeof(float)*NPATH);\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_z, sizeof(float)*2*h_N*NPATH) );\n",
        "\n",
        "  // define constants and transfer to GPU\n",
        "\n",
        "  h_T     = 1.0f;\n",
        "  h_r     = 0.05f;\n",
        "  h_sigma = 0.1f;\n",
        "  h_rho   = 0.5f;\n",
        "  h_alpha = sqrt(1.0f-h_rho*h_rho);\n",
        "  h_dt    = 1.0f/h_N;\n",
        "  h_con1  = 1.0f + h_r*h_dt;\n",
        "  h_con2  = sqrt(h_dt)*h_sigma;\n",
        "\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n",
        "\n",
        "  // random number generation\n",
        "\n",
        "  curandGenerator_t gen;\n",
        "  checkCudaErrors( curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT) );\n",
        "  checkCudaErrors( curandSetPseudoRandomGeneratorSeed(gen, 1234ULL) );\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( curandGenerateNormal(gen, d_z, 2*h_N*NPATH, 0.0f, 1.0f) );\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  printf(\"CURAND normal RNG  execution time (ms): %f,  samples/sec: %e \\n\",\n",
        "          milli, 2.0*h_N*NPATH/(0.001*milli));\n",
        "\n",
        "  // execute kernel and time it\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  pathcalc<<<NPATH/128, 128>>>(d_z, d_v);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "  printf(\"Monte Carlo kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  // copy back results\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n",
        "                   cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // compute average\n",
        "\n",
        "  sum1 = 0.0;\n",
        "  sum2 = 0.0;\n",
        "  for (int i=0; i<NPATH; i++) {\n",
        "    sum1 += h_v[i];\n",
        "    sum2 += h_v[i]*h_v[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n",
        "\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n",
        "\n",
        "  // Tidy up library\n",
        "\n",
        "  checkCudaErrors( curandDestroyGenerator(gen) );\n",
        "\n",
        "  // Release memory and exit cleanly\n",
        "\n",
        "  free(h_v);\n",
        "  checkCudaErrors( cudaFree(d_v) );\n",
        "  checkCudaErrors( cudaFree(d_z) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "5cecd518-5cab-4684-ccfe-e21da584e869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prac2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.  Note that the compilation links in the CUDA random number generation library cuRAND.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2.cu -o prac2 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "80eaa4ee-577d-4f59-906d-190f41fe2010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem, 36 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "627b83c8-0f86-458d-9dba-8dcb0775939a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "CURAND normal RNG  execution time (ms): 164.582047,  samples/sec: 1.166591e+10 \n",
            "Monte Carlo kernel execution time (ms): 29.530111 \n",
            "\n",
            "Average value and standard deviation of error  =    0.41786269    0.00015237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(5)"
      ],
      "metadata": {
        "id": "PYSxM81Hne5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Version 2"
      ],
      "metadata": {
        "id": "da5I1GJCI2qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2_v2.cu\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__constant__ int   N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "__global__ void pathcalc(float *d_z, float *d_v)\n",
        "{\n",
        "  float s1, s2, y1, y2, payoff;\n",
        "  int   ind;\n",
        "\n",
        "  // move array pointers to correct position\n",
        "\n",
        "  // version 1\n",
        "  //ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "  // version 2\n",
        "  ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x;\n",
        "\n",
        "\n",
        "  // path calculation\n",
        "\n",
        "  s1 = 1.0f;\n",
        "  s2 = 1.0f;\n",
        "\n",
        "  for (int n=0; n<N; n++) {\n",
        "    y1   = d_z[ind];\n",
        "    // version 1\n",
        "    //ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    ind += 1;\n",
        "\n",
        "    y2   = rho*y1 + alpha*d_z[ind];\n",
        "    // version 1\n",
        "    //ind += blockDim.x;      // shift pointer to next element\n",
        "    // version 2\n",
        "    ind += 1;\n",
        "\n",
        "    s1 = s1*(con1 + con2*y1);\n",
        "    s2 = s2*(con1 + con2*y2);\n",
        "  }\n",
        "\n",
        "  // put payoff value into device array\n",
        "\n",
        "  payoff = 0.0f;\n",
        "  if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n",
        "\n",
        "  d_v[threadIdx.x + blockIdx.x*blockDim.x] = payoff;\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int     NPATH=9600000, h_N=100;\n",
        "  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "  float  *h_v, *d_v, *d_z;\n",
        "  double  sum1, sum2;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory on host and device\n",
        "\n",
        "  h_v = (float *)malloc(sizeof(float)*NPATH);\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_z, sizeof(float)*2*h_N*NPATH) );\n",
        "\n",
        "  // define constants and transfer to GPU\n",
        "\n",
        "  h_T     = 1.0f;\n",
        "  h_r     = 0.05f;\n",
        "  h_sigma = 0.1f;\n",
        "  h_rho   = 0.5f;\n",
        "  h_alpha = sqrt(1.0f-h_rho*h_rho);\n",
        "  h_dt    = 1.0f/h_N;\n",
        "  h_con1  = 1.0f + h_r*h_dt;\n",
        "  h_con2  = sqrt(h_dt)*h_sigma;\n",
        "\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n",
        "\n",
        "  // random number generation\n",
        "\n",
        "  curandGenerator_t gen;\n",
        "  checkCudaErrors( curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT) );\n",
        "  checkCudaErrors( curandSetPseudoRandomGeneratorSeed(gen, 1234ULL) );\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( curandGenerateNormal(gen, d_z, 2*h_N*NPATH, 0.0f, 1.0f) );\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  printf(\"CURAND normal RNG  execution time (ms): %f,  samples/sec: %e \\n\",\n",
        "          milli, 2.0*h_N*NPATH/(0.001*milli));\n",
        "\n",
        "  // execute kernel and time it\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  pathcalc<<<NPATH/128, 128>>>(d_z, d_v);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "  printf(\"Monte Carlo kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  // copy back results\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n",
        "                   cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // compute average\n",
        "\n",
        "  sum1 = 0.0;\n",
        "  sum2 = 0.0;\n",
        "  for (int i=0; i<NPATH; i++) {\n",
        "    sum1 += h_v[i];\n",
        "    sum2 += h_v[i]*h_v[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n",
        "\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n",
        "\n",
        "  // Tidy up library\n",
        "\n",
        "  checkCudaErrors( curandDestroyGenerator(gen) );\n",
        "\n",
        "  // Release memory and exit cleanly\n",
        "\n",
        "  free(h_v);\n",
        "  checkCudaErrors( cudaFree(d_v) );\n",
        "  checkCudaErrors( cudaFree(d_z) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqbIXAtQI2Fx",
        "outputId": "f956c4fe-0f59-4d6b-9f44-56542373eba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac2_v2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2_v2.cu -o prac2_v2 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0c2f9d-c1cd-40f1-c7ba-7cf9645f23a3",
        "id": "7OyBUJRCI-EK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem, 36 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f93ace7-9d10-4de0-9433-1d3d5a3c51cc",
        "id": "Ez2RnHDRI-EU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "CURAND normal RNG  execution time (ms): 110.284798,  samples/sec: 1.740947e+10 \n",
            "Monte Carlo kernel execution time (ms): 97.590530 \n",
            "\n",
            "Average value and standard deviation of error  =    0.41793859    0.00015237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">"
      ],
      "metadata": {
        "id": "8zQxtMpInpVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(6)"
      ],
      "metadata": {
        "id": "BtUBKyZMnr6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Version 1, the index is calculated as follows `ind = threadIdx.x + 2*N*blockIdx.x*blockDim.x`, ind is incremended by `blockDim.x`, which causes consecutive threads within a warp. This access pattern is coalesced, meaning the GPU fetches memory efficiently by grouping requests into fewer transactions, maximizing memory bandwidth."
      ],
      "metadata": {
        "id": "6Uy-YNLYn5by"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">In Version 2, the index is calculated as `ind = 2*N*threadIdx.x + 2*N*blockIdx.x*blockDim.x`, each thread access  non-consecutive memory locations, leading to non-coalesced memory access. This increases the number of memory transactions, reducing performance.\n",
        "\n",
        "\n",
        ">*Note:Version 2 would be faster if we had very large cache , because it would exploit the cache locality, but this is just hypothesis since we only have small cache memory.*"
      ],
      "metadata": {
        "id": "--TeAHglr8hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(7)"
      ],
      "metadata": {
        "id": "XOgDKoVwnusG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2_time.cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "__constant__ int N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Kernel routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "__global__ void pathcalc(float *d_z, float *d_v) {\n",
        "    float s1, s2, y1, y2, payoff;\n",
        "    int ind;\n",
        "\n",
        "    // Version 1\n",
        "    ind = threadIdx.x + 2 * N * blockIdx.x * blockDim.x;\n",
        "\n",
        "    s1 = 1.0f;\n",
        "    s2 = 1.0f;\n",
        "\n",
        "    for (int n = 0; n < N; n++) {\n",
        "        y1 = d_z[ind];\n",
        "        ind += blockDim.x;\n",
        "        y2 = rho * y1 + alpha * d_z[ind];\n",
        "        ind += blockDim.x;\n",
        "        s1 = s1 * (con1 + con2 * y1);\n",
        "        s2 = s2 * (con1 + con2 * y2);\n",
        "    }\n",
        "\n",
        "    payoff = 0.0f;\n",
        "    if (fabs(s1 - 1.0f) < 0.1f && fabs(s2 - 1.0f) < 0.1f) {\n",
        "        payoff = exp(-r * T);\n",
        "    }\n",
        "    d_v[threadIdx.x + blockIdx.x * blockDim.x] = payoff;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "int main(int argc, const char **argv) {\n",
        "    int NPATH = 9600000, h_N = 100;\n",
        "    float h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "    float *h_v, *d_v, *d_z;\n",
        "    double sum1 = 0.0, sum2 = 0.0;\n",
        "\n",
        "    // Initialize CUDA\n",
        "    findCudaDevice(argc, argv);\n",
        "\n",
        "    // CUDA timing variables\n",
        "    float milli;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Allocate memory\n",
        "    h_v = (float *)malloc(sizeof(float) * NPATH);\n",
        "    checkCudaErrors(cudaMalloc((void **)&d_v, sizeof(float) * NPATH));\n",
        "    checkCudaErrors(cudaMalloc((void **)&d_z, sizeof(float) * 2 * h_N * NPATH));\n",
        "\n",
        "    // Define constants and transfer to GPU\n",
        "    h_T = 1.0f;\n",
        "    h_r = 0.05f;\n",
        "    h_sigma = 0.1f;\n",
        "    h_rho = 0.5f;\n",
        "    h_alpha = sqrt(1.0f - h_rho * h_rho);\n",
        "    h_dt = 1.0f / h_N;\n",
        "    h_con1 = 1.0f + h_r * h_dt;\n",
        "    h_con2 = sqrt(h_dt) * h_sigma;\n",
        "\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(N, &h_N, sizeof(h_N)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(T, &h_T, sizeof(h_T)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(r, &h_r, sizeof(h_r)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(sigma, &h_sigma, sizeof(h_sigma)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(rho, &h_rho, sizeof(h_rho)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(alpha, &h_alpha, sizeof(h_alpha)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(dt, &h_dt, sizeof(h_dt)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)));\n",
        "\n",
        "    // Generate random numbers using CURAND\n",
        "    curandGenerator_t gen;\n",
        "    checkCudaErrors(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n",
        "    checkCudaErrors(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    checkCudaErrors(curandGenerateNormal(gen, d_z, 2 * h_N * NPATH, 0.0f, 1.0f));\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milli, start, stop);\n",
        "    //printf(\"CURAND normal RNG execution time (ms): %f, samples/sec: %e \\n\", milli, 2.0 * h_N * NPATH / (0.001 * milli));\n",
        "\n",
        "    // Execute kernel and time it\n",
        "    cudaEventRecord(start);\n",
        "    pathcalc<<<NPATH / 128, 128>>>(d_z, d_v);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milli, start, stop);\n",
        "    //printf(\"Monte Carlo kernel execution time (ms): %f \\n\", milli);\n",
        "\n",
        "    // Copy results back to host\n",
        "    checkCudaErrors(cudaMemcpy(h_v, d_v, sizeof(float) * NPATH, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // total data loaded and effective transfer rate\n",
        "    double total_data_gb = (double)NPATH * h_N * 2 * 4 / (1024 * 1024 * 1024);  // in GB\n",
        "    double transfer_rate = total_data_gb / (milli / 1000);  // in GB/s\n",
        "\n",
        "    printf(\"Total data loaded from device memory: %.2f GB\\n\", total_data_gb);\n",
        "    printf(\"Effective memory transfer rate: %.2f GB/s\\n\", transfer_rate);\n",
        "\n",
        "    // Compare to peak bandwidth\n",
        "    printf(\"Peak memory bandwidth of T4 GPU: 300 GB/s\\n\");\n",
        "\n",
        "    // Compute average and standard deviation\n",
        "    for (int i = 0; i < NPATH; i++) {\n",
        "        sum1 += h_v[i];\n",
        "        sum2 += h_v[i] * h_v[i];\n",
        "    }\n",
        "\n",
        "    //printf(\"\\nAverage value: %13.8f\\n\", sum1 / NPATH);\n",
        "    //printf(\"Standard deviation of error: %13.8f\\n\\n\", sqrt((sum2 / NPATH - (sum1 / NPATH) * (sum1 / NPATH)) / NPATH));\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_v);\n",
        "    checkCudaErrors(cudaFree(d_v));\n",
        "    checkCudaErrors(cudaFree(d_z));\n",
        "    checkCudaErrors(curandDestroyGenerator(gen));\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaQp8z9qtW7t",
        "outputId": "1713fff5-2e7e-4f9b-b390-e76be196eba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac2_time.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2_time.cu -o prac2_time -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6379b761-1bac-4845-f66d-e1058271dbc4",
        "id": "tZtRSsK3tXqC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem, 36 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e872a4-9fa2-442e-96d7-c851eefe4569",
        "id": "ln9tEG2jtXqG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Total data loaded from device memory: 7.15 GB\n",
            "Effective memory transfer rate: 242.33 GB/s\n",
            "Peak memory bandwidth of T4 GPU: 300 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8)"
      ],
      "metadata": {
        "id": "Qc8sfcWqnwih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2_avg.cu\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "__constant__ int N;\n",
        "__constant__ float a = 1.0f;\n",
        "__constant__ float b = 2.0f;\n",
        "__constant__ float c = 3.0f;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Kernel routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "__global__ void pathcalc(float *d_z, float *d_v) {\n",
        "    int ind = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    float total = 0.0f;\n",
        "\n",
        "    for (int n = 0; n < N; n++) {\n",
        "        // Fetch first random num.\n",
        "        float z = d_z[ind];\n",
        "        ind += blockDim.x;  // Move to next random num.\n",
        "\n",
        "        // Compute a * z^2 + b * z + c\n",
        "        total += a * z * z + b * z + c;\n",
        "\n",
        "        // next random num. for next iteration\n",
        "        ind += blockDim.x;\n",
        "    }\n",
        "\n",
        "    // Store the average of 100 samples in device array\n",
        "     d_v[threadIdx.x + blockIdx.x * blockDim.x] = total / 100.0f;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "int main(int argc, const char **argv) {\n",
        "    int NPATH = 9600000, h_N = 100;\n",
        "    float h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "    float *h_v, *d_v, *d_z;\n",
        "    double sum1 = 0.0;\n",
        "\n",
        "    // Initialize CUDA\n",
        "    findCudaDevice(argc, argv);\n",
        "\n",
        "    // Initialize CUDA timing\n",
        "    float milli;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Allocate memory on host and device\n",
        "    h_v = (float *)malloc(sizeof(float) * NPATH);\n",
        "    checkCudaErrors(cudaMalloc((void **)&d_v, sizeof(float) * NPATH));\n",
        "    checkCudaErrors(cudaMalloc((void **)&d_z, sizeof(float) * 2 * h_N * NPATH));\n",
        "\n",
        "\n",
        "    h_T = 1.0f;\n",
        "    h_r = 0.05f;\n",
        "    h_sigma = 0.1f;\n",
        "    h_rho = 0.5f;\n",
        "    h_alpha = sqrt(1.0f - h_rho * h_rho);\n",
        "    h_dt = 1.0f / h_N;\n",
        "    h_con1 = 1.0f + h_r * h_dt;\n",
        "    h_con2 = sqrt(h_dt) * h_sigma;\n",
        "\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(N, &h_N, sizeof(h_N)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(T, &h_T, sizeof(h_T)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(r, &h_r, sizeof(h_r)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(sigma, &h_sigma, sizeof(h_sigma)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(rho, &h_rho, sizeof(h_rho)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(alpha, &h_alpha, sizeof(h_alpha)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(dt, &h_dt, sizeof(h_dt)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)));\n",
        "    checkCudaErrors(cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)));\n",
        "\n",
        "    // Random number generation\n",
        "    curandGenerator_t gen;\n",
        "    checkCudaErrors(curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT));\n",
        "    checkCudaErrors(curandSetPseudoRandomGeneratorSeed(gen, 1234ULL));\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    checkCudaErrors(curandGenerateNormal(gen, d_z, 2 * h_N * NPATH, 0.0f, 1.0f));\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milli, start, stop);\n",
        "    //printf(\"CURAND normal RNG execution time (ms): %f,  samples/sec: %e \\n\", milli, 2.0 * h_N * NPATH / (0.001 * milli));\n",
        "\n",
        "    // Execute kernel and time it\n",
        "    cudaEventRecord(start);\n",
        "    pathcalc<<<NPATH / 128, 128>>>(d_z, d_v);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milli, start, stop);\n",
        "    getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "    //printf(\"Monte Carlo kernel execution time (ms): %f \\n\", milli);\n",
        "\n",
        "    // Copy back results\n",
        "    checkCudaErrors(cudaMemcpy(h_v, d_v, sizeof(float) * NPATH, cudaMemcpyDeviceToHost));\n",
        "\n",
        "    // Compute average\n",
        "    for (int i = 0; i < NPATH; i++) {\n",
        "        sum1 += h_v[i];\n",
        "    }\n",
        "\n",
        "    printf(\"\\nFinal average value: %13.8f\\n\", sum1 / NPATH);\n",
        "    printf(\"Expected value a + c = 4.0 (Approx. the same)\\n\");\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_v);\n",
        "    checkCudaErrors(cudaFree(d_v));\n",
        "    checkCudaErrors(cudaFree(d_z));\n",
        "    checkCudaErrors(curandDestroyGenerator(gen));\n",
        "    cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUKYt5mgoDWw",
        "outputId": "16bbc454-8cd3-4452-b9da-0461d1080732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac2_avg.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2_avg.cu -o prac2_avg -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052ada59-e25d-43b4-9eb9-6f7083592fae",
        "id": "x1WHJf6UpZlF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem, 48 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2_avg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b57589-a4e1-47b5-9bff-ec1f587c3fcf",
        "id": "3jENQwOVpZlJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "Final average value:    3.99949094\n",
            "Expected value a + c = 4.0 (Approx. the same)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extra"
      ],
      "metadata": {
        "id": "MuG2FP4o1Kd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code block you can modify the code to complete the Practical 2 exercises as prescribed in the Instructions for this practical.\n",
        "\n",
        "It is perhaps better to copy the Code cell (on my system this is done by using the mouse right-click) and paste it to form a new Code cell, so that the original cell uses Version 1, and the new cell uses Version 2.  You can then make a further copy when you do the new application for the final step in the practical.\n",
        "\n",
        "Remember to first make your own copy of the notebook so that you are able to edit it.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should add your name to the title of the notebook (as in \"Practical 2 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Lastly, the instructions below create, compile and execute a version of the code which generates the random numbers on-the-fly within each kernel using the device-level cuRAND library.  This gives the very best performance because the random numbers no longer are being transferred between the GPU and the device memory.\n"
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prac2_device.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU version of Monte Carlo algorithm using NVIDIA's CURAND library\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CUDA global constants\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__constant__ int   N;\n",
        "__constant__ float T, r, sigma, rho, alpha, dt, con1, con2;\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel routines -- see sections 3.5, 3.6 in cuRAND documentation\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void RNG_init(curandState *state)\n",
        "{\n",
        "  // RNG initialisation with id-based skipahead\n",
        "  int id = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  curand_init(1234, id, 0, &state[id]);\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void pathcalc(curandState *device_state, float *d_v,\n",
        "                         int mpath, int NPATH)\n",
        "{\n",
        "  float s1, s2, y1, y2, payoff;\n",
        "\n",
        "  int id = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  curandState_t state = device_state[id];\n",
        "\n",
        "  for(int m=0; m<mpath; m++) {\n",
        "    s1 = 1.0f;\n",
        "    s2 = 1.0f;\n",
        "\n",
        "    for (int n=0; n<N; n++) {\n",
        "      y1 = curand_normal(&state);\n",
        "      y2 = rho*y1 + alpha*curand_normal(&state);\n",
        "\n",
        "      s1 = s1*(con1 + con2*y1);\n",
        "      s2 = s2*(con1 + con2*y2);\n",
        "    }\n",
        "\n",
        "    // put payoff value into device array\n",
        "\n",
        "    payoff = 0.0f;\n",
        "    if ( fabs(s1-1.0f)<0.1f && fabs(s2-1.0f)<0.1f ) payoff = exp(-r*T);\n",
        "\n",
        "    int payoff_id = id + m*gridDim.x*blockDim.x;\n",
        "    if (payoff_id < NPATH) d_v[payoff_id] = payoff;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int     NPATH=9600000, h_N=100;\n",
        "  float   h_T, h_r, h_sigma, h_rho, h_alpha, h_dt, h_con1, h_con2;\n",
        "  float  *h_v, *d_v;\n",
        "  double  sum1, sum2;\n",
        "  curandState *state;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory on host and device\n",
        "\n",
        "  h_v = (float *)malloc(sizeof(float)*NPATH);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_v, sizeof(float)*NPATH) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&state, sizeof(curandState)*NPATH) );\n",
        "\n",
        "  // printf(\"size of curandState is %d bytes\\n\",sizeof(curandState));\n",
        "\n",
        "  // define constants and transfer to GPU\n",
        "\n",
        "  h_T     = 1.0f;\n",
        "  h_r     = 0.05f;\n",
        "  h_sigma = 0.1f;\n",
        "  h_rho   = 0.5f;\n",
        "  h_alpha = sqrt(1.0f-h_rho*h_rho);\n",
        "  h_dt    = 1.0f/h_N;\n",
        "  h_con1  = 1.0f + h_r*h_dt;\n",
        "  h_con2  = sqrt(h_dt)*h_sigma;\n",
        "\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(N,    &h_N,    sizeof(h_N)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(T,    &h_T,    sizeof(h_T)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(r,    &h_r,    sizeof(h_r)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(sigma,&h_sigma,sizeof(h_sigma)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(rho,  &h_rho,  sizeof(h_rho)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(alpha,&h_alpha,sizeof(h_alpha)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(dt,   &h_dt,   sizeof(h_dt)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con1, &h_con1, sizeof(h_con1)) );\n",
        "  checkCudaErrors( cudaMemcpyToSymbol(con2, &h_con2, sizeof(h_con2)) );\n",
        "\n",
        "  // calculate theoretical occupancy -- see Pro Tip blog article:\n",
        "  // https://developer.nvidia.com/blog/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/\n",
        "\n",
        "  int device;\n",
        "  cudaDeviceProp props;\n",
        "  cudaGetDevice(&device);\n",
        "  cudaGetDeviceProperties(&props, device);\n",
        "\n",
        "  int maxActiveBlocks, blockSize=128;\n",
        "  cudaOccupancyMaxActiveBlocksPerMultiprocessor( &maxActiveBlocks,\n",
        "                                                 pathcalc, blockSize, 0);\n",
        "  printf(\"maxActiveBlocks/SM = %d \\n\",maxActiveBlocks);\n",
        "  printf(\"number of SMs      = %d \\n\",props.multiProcessorCount);\n",
        "  int blocks = maxActiveBlocks*props.multiProcessorCount;\n",
        "\n",
        "  // execute kernels\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  RNG_init<<<blocks, 128>>>(state);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"RNG_init execution failed\\n\");\n",
        "  printf(\"RNG_init kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  int paths_per_thread = (NPATH-1)/(128*blocks) + 1;\n",
        "  cudaEventRecord(start);\n",
        "  pathcalc<<<blocks, 128>>>(state,d_v,paths_per_thread,NPATH);\n",
        "  cudaEventRecord(stop);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  getLastCudaError(\"pathcalc execution failed\\n\");\n",
        "  printf(\"pathcalc kernel execution time (ms): %f \\n\",milli);\n",
        "\n",
        "  // copy back results\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_v, d_v, sizeof(float)*NPATH,\n",
        "                   cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // compute average\n",
        "\n",
        "  sum1 = 0.0;\n",
        "  sum2 = 0.0;\n",
        "  for (int i=0; i<NPATH; i++) {\n",
        "    sum1 += h_v[i];\n",
        "    sum2 += h_v[i]*h_v[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nAverage value and standard deviation of error  = %13.8f %13.8f\\n\\n\",\n",
        "\t sum1/NPATH, sqrt((sum2/NPATH - (sum1/NPATH)*(sum1/NPATH))/NPATH) );\n",
        "\n",
        "  // Release memory and exit cleanly\n",
        "\n",
        "  free(h_v);\n",
        "  checkCudaErrors( cudaFree(d_v) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8xscLewbPlF",
        "outputId": "faf8b4f8-f3c3-4319-d1b9-e7208d270b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prac2_device.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prac2_device.cu -o prac2_device -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart -lcurand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGXiohVT5OR",
        "outputId": "aba6bb76-a61b-4aa1-9cf7-a7cb36e103b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 218048 bytes gmem, 108 bytes cmem[3], 64 bytes cmem[4]\n",
            "ptxas info    : Compiling entry function '_Z8pathcalcP17curandStateXORWOWPfii' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8pathcalcP17curandStateXORWOWPfii\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 376 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z8RNG_initP17curandStateXORWOW' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z8RNG_initP17curandStateXORWOW\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 32 registers, 360 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./prac2_device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfyCekjazPh",
        "outputId": "1b003c32-ff58-4b0e-c2cc-93a7a4344ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "maxActiveBlocks/SM = 8 \n",
            "number of SMs      = 40 \n",
            "RNG_init kernel execution time (ms): 1.659776 \n",
            "pathcalc kernel execution time (ms): 23.670401 \n",
            "\n",
            "Average value and standard deviation of error  =    0.41802440    0.00015237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again the final piece of code is to terminate the runtime."
      ],
      "metadata": {
        "id": "Fa5hiDuchY7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "Q8twCtvWhd9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EgtR8k3lPik-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}