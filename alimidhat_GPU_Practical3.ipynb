{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "lWMPPgHS8M1x",
        "FlosZmWY8RP_",
        "NzPdqztC-ZvH",
        "AAlmKVzJGX73",
        "doc8xBuCIStR",
        "61mCj-ErIYzE",
        "vL3lHvoxJ1Ow",
        "mCVRo_qGMv8u",
        "xSAhgGUCNkWf",
        "qOs8N6U0OuEe",
        "LvOuEpZqOqDL",
        "4GggHEcmPW8Z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Midhat/CUDA/blob/main/alimidhat_GPU_Practical3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Ali Midhat Abdelgadir Abdalla**"
      ],
      "metadata": {
        "id": "Bm1CtzwIdsAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs, July 22-26, 2024**\n",
        "\n",
        "# **Practical 3**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify with the instruction below the details of the GPU which is available to you.  "
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "d4f8103f-eb09-4522-aa7f-60cb53cd56df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 10 15:10:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "First we upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "54925224-fdfb-4a81-c7ff-f459b496e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-12 17:51:04--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K   158KB/s    in 0.2s    \n",
            "\n",
            "2025-02-12 17:51:05 (158 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2025-02-12 17:51:06--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-12 17:51:06 (360 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file laplace3d.cu which includes within it a reference C++ routine against which the CUDA results are compared."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(3)"
      ],
      "metadata": {
        "id": "lWMPPgHS8M1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 16\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // r only?\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\tind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=512, NY=512, NZ=512, // data points\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "319fb1f7-bedb-491b-948c-95902ab44ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d.cu -o laplace3d -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "2ccb4d93-5aa6-4e0c-b2dd-9a2dbfe741c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "40b435bd-2af9-45ad-ac24-ce72bf65dae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 117.4 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 27489.6 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 181.2 (ms) \n",
            "\n",
            "Copy u2 to host: 116.3 (ms) \n",
            "\n",
            "rms error = 0.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(4)"
      ],
      "metadata": {
        "id": "FlosZmWY8RP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_4.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 16\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // r only?\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, // data points\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC1cyx2K8Slw",
        "outputId": "6d2101f4-c8b7-45d1-a54f-094643306bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d_4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_4.cu -o laplace3d_4 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159c601b-fa95-40dd-a080-2577e66e37d1",
        "id": "6x1wX_Tj8u8I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf91ad5-dbca-4e8a-b53d-27b03b6ffa43",
        "id": "2KhR--W38u8O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 932.3 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 1953.5 (ms) \n",
            "\n",
            "Copy u2 to host: 3414.4 (ms) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(5)"
      ],
      "metadata": {
        "id": "NzPdqztC-ZvH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vRQeys9L-bMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_5.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 128\n",
        "#define BLOCK_Y 8\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2) // r only?\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, // data points\n",
        "            REPEAT=20, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c188f0f-4900-471b-fc6f-d338f8f2c4dd",
        "id": "rqGXEmoZ-dR9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d_5.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_5.cu -o laplace3d_5 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfc0da9-ca80-482f-feb0-a720fb2ef944",
        "id": "I1k-U8Se-dR_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e6708b-2121-4f0e-e409-519e32900e83",
        "id": "EDGPgT35-dSB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 911.1 (ms) \n",
            "\n",
            "20x GPU_laplace3d: 1231.0 (ms) \n",
            "\n",
            "Copy u2 to host: 3040.4 (ms) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Results"
      ],
      "metadata": {
        "id": "cHhBsPh3b2e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Block size of `(16*16)` ==> `1953.5` (ms)\\\n",
        "> Block size of `(32*32)` ==> `1283.2` (ms) \\\n",
        "> Block size of `(64*8)` ==> `1300.2` (ms) \\\n",
        "> Block size of `(128*8)` ==> `1231.0` (ms)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1aHkKcdD_QD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">"
      ],
      "metadata": {
        "id": "ke7bbn7B_aC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(6)"
      ],
      "metadata": {
        "id": "AAlmKVzJGX73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Original version"
      ],
      "metadata": {
        "id": "doc8xBuCIStR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_new.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 16\n",
        "#define BLOCK_Y 4\n",
        "#define BLOCK_Z 4\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157cbfec-1189-42f1-9a14-a1f39eddddac",
        "id": "pnkMKE1iIPfZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_new.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_new.cu -o laplace3d_new -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f494d98f-2b6c-4607-9411-6adaac9042ba",
        "id": "l5V9AK2FIPfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412851f0-e7c6-4069-bb87-83610b78ca86",
        "id": "PAsnaebkIPfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 919.2 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 228977.4 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 968.6 (ms) \n",
            "\n",
            "Copy u2 to host: 905.0 (ms) \n",
            "\n",
            "rms error = 0.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`BLOCK_X=8`, `BLOCK_Y=8`, and `BLOCK_Z=8`"
      ],
      "metadata": {
        "id": "61mCj-ErIYzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_optimized_2.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 8\n",
        "#define BLOCK_Y 8\n",
        "#define BLOCK_Z 8\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "    h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62597942-23fc-4a6f-d31c-d3afeb6579b7",
        "id": "ylLijt-xIf4h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_optimized_2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_optimized_2.cu -o laplace3d_optimized_2 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac019970-0aba-4231-f28d-c46313b3829b",
        "id": "k8f_tZKNIf4k"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_optimized_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac21caf-2dff-494a-d607-e49b6a304594",
        "id": "iohLs4x5If4l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 926.4 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 225967.2 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 1182.5 (ms) \n",
            "\n",
            "Copy u2 to host: 899.1 (ms) \n",
            "\n",
            "rms error = 0.000000 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`BLOCK_X=32`, `BLOCK_Y=4`, and `BLOCK_Z=4`"
      ],
      "metadata": {
        "id": "vL3lHvoxJ1Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_optimized_3.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 32\n",
        "#define BLOCK_Y 4\n",
        "#define BLOCK_Z 4\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8c0c2c-72dd-4e07-8e72-fd4b2a859962",
        "id": "5XluSHi6J1O1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d_optimized_3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_optimized_3.cu -o laplace3d_optimized_3 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb43355-b6b2-47db-ad15-173bcce91c34",
        "id": "Yi5S9kveJ1O3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_optimized_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a86b3f-ff11-4f86-81df-a96cf1d6a28f",
        "id": "1qjqpT3eJ1O4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 908.8 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 942.6 (ms) \n",
            "\n",
            "Copy u2 to host: 3019.8 (ms) \n",
            "\n",
            "rms error = 0.066320 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`BLOCK_X=32`, `BLOCK_Y=4`, and `BLOCK_Z=2`"
      ],
      "metadata": {
        "id": "mCVRo_qGMv8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_optimized_4.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 32\n",
        "#define BLOCK_Y 4\n",
        "#define BLOCK_Z 2\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce872fb1-1118-4d0d-f85c-b252a473583b",
        "id": "Hus5urSVM6_v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_optimized_4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_optimized_4.cu -o laplace3d_optimized_4 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee28b4ea-bf8b-40c1-a39d-b4996abfce73",
        "id": "4B97t_pGM6_3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_optimized_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40c8154-77c5-4bd6-867e-7837ab173d45",
        "id": "1NUxsjDXM6_4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 902.7 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 1035.5 (ms) \n",
            "\n",
            "Copy u2 to host: 3278.7 (ms) \n",
            "\n",
            "rms error = 0.066320 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`BLOCK_X=32`, `BLOCK_Y=2`, and `BLOCK_Z=4`"
      ],
      "metadata": {
        "id": "xSAhgGUCNkWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_optimized_5.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 32\n",
        "#define BLOCK_Y 2\n",
        "#define BLOCK_Z 4\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088d47f3-4b93-402a-d4a0-15f10c4118b6",
        "id": "flabnbRoNkWn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_optimized_5.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_optimized_5.cu -o laplace3d_optimized_5 -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6526b0a0-62b4-4692-fa31-fd19bff079cc",
        "id": "RQtdd3nSNkWp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_optimized_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27818d1d-48f5-43bc-a6e0-306e804ef6b4",
        "id": "jNQq1Ez2NkWq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 900.0 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 897.7 (ms) \n",
            "\n",
            "Copy u2 to host: 3030.1 (ms) \n",
            "\n",
            "rms error = 0.066320 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results: (NX,NY, NZ) ==> 512\n",
        "`block size (32, 4, 4)` ==> `153.9 (ms)`\n",
        "\n",
        "`block size (16, 4, 4)` ==> `149.1 (ms)` `Original`\n",
        "\n",
        "`Block size (8, 8, 8)` ==> `248.4 (ms)`\n",
        "\n",
        "`Block size (32, 4, 2)` ==> `139.3 (ms)` `second BEST`\n",
        "\n",
        "`Block size (32, 2, 4)` ==> `134.8 (ms)` `BEST`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UqIEp9tJLhvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results: (NX,NY, NZ) ==> 1024\n",
        "`block size (32, 4, 4)` ==> `942.6 (ms)`\n",
        "\n",
        "`block size (16, 4, 4)` ==> `968.6 (ms)` `Original`\n",
        "\n",
        "`Block size (8, 8, 8)` ==> `1182.5 (ms)`\n",
        "\n",
        "`Block size (32, 4, 2)` ==> `1035.5 (ms)`\n",
        "\n",
        "`Block size (32, 2, 4)` ==> `897.7 (ms)` `BEST`"
      ],
      "metadata": {
        "id": "IwfPCmdYdnip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code block you can modify the code to complete the initial Practical 3 exercises. Remember to first make your own copy of the notebook so that you are able to edit it.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should again add your name to the title of the notebook (as in \"Practical 3 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "For the later parts of Practical 3, the instructions below create, compile and execute a second version of the code in which each CUDA thread computes the value for just one 3D grid point."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(7)"
      ],
      "metadata": {
        "id": "qOs8N6U0OuEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_new.cu\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// define kernel block size\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#define BLOCK_X 32\n",
        "#define BLOCK_Y 2\n",
        "#define BLOCK_Z 4\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*BLOCK_X;\n",
        "  j    = threadIdx.y + blockIdx.y*BLOCK_Y;\n",
        "  k    = threadIdx.z + blockIdx.z*BLOCK_Z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024,\n",
        "            REPEAT=20, bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X;\n",
        "  by = 1 + (NY-1)/BLOCK_Y;\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8xscLewbPlF",
        "outputId": "db808cd8-0f81-4236-fca8-106362a7cbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d_new.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_new.cu -o laplace3d_new -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGXiohVT5OR",
        "outputId": "693c69d4-0605-48ed-c393-e165454ef62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfyCekjazPh",
        "outputId": "395a7bbc-d0c9-42c4-c79e-57bf6e10bd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 906.5 (ms) \n",
            "\n",
            "20x GPU_laplace3d_new: 899.9 (ms) \n",
            "\n",
            "Copy u2 to host: 3437.4 (ms) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "The next instructions check how many fp32 and integer instructions are performed by the two versions"
      ],
      "metadata": {
        "id": "8IUnwap2F64l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d\n",
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kXdNtggGUv8",
        "outputId": "c6226452-ffea-454d-ab4c-da99113fed9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==ERROR== './laplace3d' does not exist or is not an executable. Please make sure to specify the absolute path to './laplace3d' if the executable is not in the local directory.\n",
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 1050 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 955.1 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%\n",
            "==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.\n",
            "....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 1 pass\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 1 pass\n",
            "20x GPU_laplace3d_new: 78493.7 (ms) \n",
            "\n",
            "Copy u2 to host: 3671.8 (ms) \n",
            "\n",
            "==PROF== Disconnected from process 1050\n",
            "[1050] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(8)"
      ],
      "metadata": {
        "id": "LvOuEpZqOqDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./laplace3d\n",
        "!ncu ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62812c1b-9d88-4074-d9f2-d31b8d8ae816",
        "id": "1USbXCV4TCpc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 512 x 512 x 512 \n",
            "\n",
            "==PROF== Connected to process 2462 (/content/laplace3d)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 119.9 (ms) \n",
            "\n",
            "20x Gold_laplace3d: 39577.8 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 9 passes\n",
            "20x GPU_laplace3d: 5763.1 (ms) \n",
            "\n",
            "Copy u2 to host: 150.5 (ms) \n",
            "\n",
            "rms error = 0.000000 \n",
            "==PROF== Disconnected from process 2462\n",
            "[2462] laplace3d@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.92\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,349,022\n",
            "    Memory Throughput                 %        74.37\n",
            "    DRAM Throughput                   %        74.37\n",
            "    Duration                         ms         9.14\n",
            "    L1/TEX Cache Throughput           %        69.13\n",
            "    L2 Cache Throughput               %        23.80\n",
            "    SM Active Cycles              cycle 5,304,234.62\n",
            "    Compute (SM) Throughput           %        30.84\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.89\n",
            "    Achieved Active Warps Per SM           warp        30.69\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,444,489.50\n",
            "    Total DRAM Elapsed Cycles        cycle   359,743,488\n",
            "    Average L1 Active Cycles         cycle  5,304,234.62\n",
            "    Total L1 Elapsed Cycles          cycle   211,370,392\n",
            "    Average L2 Active Cycles         cycle  7,698,162.34\n",
            "    Total L2 Elapsed Cycles          cycle   250,164,352\n",
            "    Average SM Active Cycles         cycle  5,304,234.62\n",
            "    Total SM Elapsed Cycles          cycle   211,370,392\n",
            "    Average SMSP Active Cycles       cycle  5,292,588.80\n",
            "    Total SMSP Elapsed Cycles        cycle   845,481,568\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.04\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,343,129\n",
            "    Memory Throughput                 %        72.66\n",
            "    DRAM Throughput                   %        72.66\n",
            "    Duration                         ms         9.13\n",
            "    L1/TEX Cache Throughput           %        67.55\n",
            "    L2 Cache Throughput               %        23.88\n",
            "    SM Active Cycles              cycle 5,338,941.05\n",
            "    Compute (SM) Throughput           %        30.14\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.22\n",
            "    Achieved Active Warps Per SM           warp        30.47\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,459,211\n",
            "    Total DRAM Elapsed Cycles        cycle  368,414,720\n",
            "    Average L1 Active Cycles         cycle 5,338,941.05\n",
            "    Total L1 Elapsed Cycles          cycle  216,261,176\n",
            "    Average L2 Active Cycles         cycle 7,858,755.69\n",
            "    Total L2 Elapsed Cycles          cycle  249,888,672\n",
            "    Average SM Active Cycles         cycle 5,338,941.05\n",
            "    Total SM Elapsed Cycles          cycle  216,261,176\n",
            "    Average SMSP Active Cycles       cycle 5,346,482.36\n",
            "    Total SMSP Elapsed Cycles        cycle  865,044,704\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.07\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,233,647\n",
            "    Memory Throughput                 %        72.56\n",
            "    DRAM Throughput                   %        72.56\n",
            "    Duration                         ms         8.95\n",
            "    L1/TEX Cache Throughput           %        68.75\n",
            "    L2 Cache Throughput               %        24.33\n",
            "    SM Active Cycles              cycle 5,304,383.25\n",
            "    Compute (SM) Throughput           %        30.68\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.04\n",
            "    Achieved Active Warps Per SM           warp        30.09\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   32,882,743\n",
            "    Total DRAM Elapsed Cycles        cycle  362,549,248\n",
            "    Average L1 Active Cycles         cycle 5,304,383.25\n",
            "    Total L1 Elapsed Cycles          cycle  212,503,776\n",
            "    Average L2 Active Cycles         cycle 7,821,904.69\n",
            "    Total L2 Elapsed Cycles          cycle  244,768,768\n",
            "    Average SM Active Cycles         cycle 5,304,383.25\n",
            "    Total SM Elapsed Cycles          cycle  212,503,776\n",
            "    Average SMSP Active Cycles       cycle 5,289,630.61\n",
            "    Total SMSP Elapsed Cycles        cycle  850,015,104\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.95\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,406,395\n",
            "    Memory Throughput                 %        73.82\n",
            "    DRAM Throughput                   %        73.82\n",
            "    Duration                         ms         9.24\n",
            "    L1/TEX Cache Throughput           %        67.90\n",
            "    L2 Cache Throughput               %        23.39\n",
            "    SM Active Cycles              cycle 5,300,282.83\n",
            "    Compute (SM) Throughput           %        30.30\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.89\n",
            "    Achieved Active Warps Per SM           warp        31.00\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,793,309.50\n",
            "    Total DRAM Elapsed Cycles        cycle   366,206,976\n",
            "    Average L1 Active Cycles         cycle  5,300,282.83\n",
            "    Total L1 Elapsed Cycles          cycle   215,138,936\n",
            "    Average L2 Active Cycles         cycle  7,920,044.16\n",
            "    Total L2 Elapsed Cycles          cycle   252,847,232\n",
            "    Average SM Active Cycles         cycle  5,300,282.83\n",
            "    Total SM Elapsed Cycles          cycle   215,138,936\n",
            "    Average SMSP Active Cycles       cycle  5,286,468.17\n",
            "    Total SMSP Elapsed Cycles        cycle   860,555,744\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.04\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,317,246\n",
            "    Memory Throughput                 %        72.42\n",
            "    DRAM Throughput                   %        72.42\n",
            "    Duration                         ms         9.09\n",
            "    L1/TEX Cache Throughput           %        67.99\n",
            "    L2 Cache Throughput               %        23.82\n",
            "    SM Active Cycles              cycle 5,301,228.75\n",
            "    Compute (SM) Throughput           %        30.36\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.45\n",
            "    Achieved Active Warps Per SM           warp        30.54\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,205,641\n",
            "    Total DRAM Elapsed Cycles        cycle  366,829,568\n",
            "    Average L1 Active Cycles         cycle 5,301,228.75\n",
            "    Total L1 Elapsed Cycles          cycle  214,723,640\n",
            "    Average L2 Active Cycles         cycle 7,739,006.59\n",
            "    Total L2 Elapsed Cycles          cycle  248,678,016\n",
            "    Average SM Active Cycles         cycle 5,301,228.75\n",
            "    Total SM Elapsed Cycles          cycle  214,723,640\n",
            "    Average SMSP Active Cycles       cycle 5,209,929.96\n",
            "    Total SMSP Elapsed Cycles        cycle  858,894,560\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.97\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,361,321\n",
            "    Memory Throughput                 %        73.91\n",
            "    DRAM Throughput                   %        73.91\n",
            "    Duration                         ms         9.16\n",
            "    L1/TEX Cache Throughput           %        68.01\n",
            "    L2 Cache Throughput               %        23.69\n",
            "    SM Active Cycles              cycle 5,364,551.53\n",
            "    Compute (SM) Throughput           %        30.33\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.17\n",
            "    Achieved Active Warps Per SM           warp        30.45\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,635,360\n",
            "    Total DRAM Elapsed Cycles        cycle  364,081,152\n",
            "    Average L1 Active Cycles         cycle 5,364,551.53\n",
            "    Total L1 Elapsed Cycles          cycle  214,897,992\n",
            "    Average L2 Active Cycles         cycle 7,997,726.97\n",
            "    Total L2 Elapsed Cycles          cycle  250,739,296\n",
            "    Average SM Active Cycles         cycle 5,364,551.53\n",
            "    Total SM Elapsed Cycles          cycle  214,897,992\n",
            "    Average SMSP Active Cycles       cycle 5,232,001.53\n",
            "    Total SMSP Elapsed Cycles        cycle  859,591,968\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.02\n",
            "    SM Frequency                    Mhz       584.99\n",
            "    Elapsed Cycles                cycle    5,385,031\n",
            "    Memory Throughput                 %        72.96\n",
            "    DRAM Throughput                   %        72.96\n",
            "    Duration                         ms         9.21\n",
            "    L1/TEX Cache Throughput           %        69.41\n",
            "    L2 Cache Throughput               %        23.61\n",
            "    SM Active Cycles              cycle 5,396,521.30\n",
            "    Compute (SM) Throughput           %        31.01\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.91\n",
            "    Achieved Active Warps Per SM           warp        30.37\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,722,060\n",
            "    Total DRAM Elapsed Cycles        cycle  369,745,920\n",
            "    Average L1 Active Cycles         cycle 5,396,521.30\n",
            "    Total L1 Elapsed Cycles          cycle  210,205,920\n",
            "    Average L2 Active Cycles         cycle 7,796,283.94\n",
            "    Total L2 Elapsed Cycles          cycle  251,848,928\n",
            "    Average SM Active Cycles         cycle 5,396,521.30\n",
            "    Total SM Elapsed Cycles          cycle  210,205,920\n",
            "    Average SMSP Active Cycles       cycle 5,263,059.74\n",
            "    Total SMSP Elapsed Cycles        cycle  840,823,680\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.06\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,347,165\n",
            "    Memory Throughput                 %        72.57\n",
            "    DRAM Throughput                   %        72.57\n",
            "    Duration                         ms         9.14\n",
            "    L1/TEX Cache Throughput           %        67.81\n",
            "    L2 Cache Throughput               %        23.77\n",
            "    SM Active Cycles              cycle 5,364,189.75\n",
            "    Compute (SM) Throughput           %        30.28\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.85\n",
            "    Achieved Active Warps Per SM           warp        30.35\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,562,116\n",
            "    Total DRAM Elapsed Cycles        cycle  369,991,680\n",
            "    Average L1 Active Cycles         cycle 5,364,189.75\n",
            "    Total L1 Elapsed Cycles          cycle  215,308,160\n",
            "    Average L2 Active Cycles         cycle 7,741,885.06\n",
            "    Total L2 Elapsed Cycles          cycle  250,077,536\n",
            "    Average SM Active Cycles         cycle 5,364,189.75\n",
            "    Total SM Elapsed Cycles          cycle  215,308,160\n",
            "    Average SMSP Active Cycles       cycle 5,285,094.69\n",
            "    Total SMSP Elapsed Cycles        cycle  861,232,640\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.00\n",
            "    SM Frequency                    Mhz       584.99\n",
            "    Elapsed Cycles                cycle    5,404,342\n",
            "    Memory Throughput                 %        72.83\n",
            "    DRAM Throughput                   %        72.83\n",
            "    Duration                         ms         9.24\n",
            "    L1/TEX Cache Throughput           %        68.46\n",
            "    L2 Cache Throughput               %        23.45\n",
            "    SM Active Cycles              cycle 5,332,231.17\n",
            "    Compute (SM) Throughput           %        30.52\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.92\n",
            "    Achieved Active Warps Per SM           warp        30.70\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,648,388\n",
            "    Total DRAM Elapsed Cycles        cycle  369,614,848\n",
            "    Average L1 Active Cycles         cycle 5,332,231.17\n",
            "    Total L1 Elapsed Cycles          cycle  213,560,432\n",
            "    Average L2 Active Cycles         cycle 7,804,736.69\n",
            "    Total L2 Elapsed Cycles          cycle  252,751,488\n",
            "    Average SM Active Cycles         cycle 5,332,231.17\n",
            "    Total SM Elapsed Cycles          cycle  213,560,432\n",
            "    Average SMSP Active Cycles       cycle 5,240,254.25\n",
            "    Total SMSP Elapsed Cycles        cycle  854,241,728\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.04\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,379,289\n",
            "    Memory Throughput                 %        72.71\n",
            "    DRAM Throughput                   %        72.71\n",
            "    Duration                         ms         9.20\n",
            "    L1/TEX Cache Throughput           %        68.12\n",
            "    L2 Cache Throughput               %        23.54\n",
            "    SM Active Cycles              cycle 5,305,929.08\n",
            "    Compute (SM) Throughput           %        30.38\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.46\n",
            "    Achieved Active Warps Per SM           warp        30.87\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,674,498\n",
            "    Total DRAM Elapsed Cycles        cycle  370,483,200\n",
            "    Average L1 Active Cycles         cycle 5,305,929.08\n",
            "    Total L1 Elapsed Cycles          cycle  214,564,824\n",
            "    Average L2 Active Cycles         cycle 7,903,994.47\n",
            "    Total L2 Elapsed Cycles          cycle  251,579,488\n",
            "    Average SM Active Cycles         cycle 5,305,929.08\n",
            "    Total SM Elapsed Cycles          cycle  214,564,824\n",
            "    Average SMSP Active Cycles       cycle 5,330,960.64\n",
            "    Total SMSP Elapsed Cycles        cycle  858,259,296\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,272,727\n",
            "    Memory Throughput                 %        72.30\n",
            "    DRAM Throughput                   %        72.30\n",
            "    Duration                         ms         9.01\n",
            "    L1/TEX Cache Throughput           %        69.18\n",
            "    L2 Cache Throughput               %        23.87\n",
            "    SM Active Cycles              cycle 5,282,800.70\n",
            "    Compute (SM) Throughput           %        30.84\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.83\n",
            "    Achieved Active Warps Per SM           warp        30.35\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 32,930,971.50\n",
            "    Total DRAM Elapsed Cycles        cycle   364,359,680\n",
            "    Average L1 Active Cycles         cycle  5,282,800.70\n",
            "    Total L1 Elapsed Cycles          cycle   211,398,744\n",
            "    Average L2 Active Cycles         cycle  7,760,859.03\n",
            "    Total L2 Elapsed Cycles          cycle   246,596,576\n",
            "    Average SM Active Cycles         cycle  5,282,800.70\n",
            "    Total SM Elapsed Cycles          cycle   211,398,744\n",
            "    Average SMSP Active Cycles       cycle  5,192,392.26\n",
            "    Total SMSP Elapsed Cycles        cycle   845,594,976\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,305,634\n",
            "    Memory Throughput                 %        72.78\n",
            "    DRAM Throughput                   %        72.78\n",
            "    Duration                         ms         9.07\n",
            "    L1/TEX Cache Throughput           %        67.12\n",
            "    L2 Cache Throughput               %        23.78\n",
            "    SM Active Cycles              cycle 5,278,129.28\n",
            "    Compute (SM) Throughput           %        29.99\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.60\n",
            "    Achieved Active Warps Per SM           warp        30.59\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,356,665.50\n",
            "    Total DRAM Elapsed Cycles        cycle   366,657,536\n",
            "    Average L1 Active Cycles         cycle  5,278,129.28\n",
            "    Total L1 Elapsed Cycles          cycle   217,363,576\n",
            "    Average L2 Active Cycles         cycle  7,847,652.25\n",
            "    Total L2 Elapsed Cycles          cycle   248,135,296\n",
            "    Average SM Active Cycles         cycle  5,278,129.28\n",
            "    Total SM Elapsed Cycles          cycle   217,363,576\n",
            "    Average SMSP Active Cycles       cycle  5,342,855.79\n",
            "    Total SMSP Elapsed Cycles        cycle   869,454,304\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.97\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,337,755\n",
            "    Memory Throughput                 %        73.71\n",
            "    DRAM Throughput                   %        73.71\n",
            "    Duration                         ms         9.12\n",
            "    L1/TEX Cache Throughput           %        68.79\n",
            "    L2 Cache Throughput               %        23.77\n",
            "    SM Active Cycles              cycle 5,346,919.03\n",
            "    Compute (SM) Throughput           %        30.65\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.14\n",
            "    Achieved Active Warps Per SM           warp        30.45\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,452,722.50\n",
            "    Total DRAM Elapsed Cycles        cycle   363,073,536\n",
            "    Average L1 Active Cycles         cycle  5,346,919.03\n",
            "    Total L1 Elapsed Cycles          cycle   212,704,328\n",
            "    Average L2 Active Cycles         cycle  7,773,253.53\n",
            "    Total L2 Elapsed Cycles          cycle   249,637,376\n",
            "    Average SM Active Cycles         cycle  5,346,919.03\n",
            "    Total SM Elapsed Cycles          cycle   212,704,328\n",
            "    Average SMSP Active Cycles       cycle  5,293,491.45\n",
            "    Total SMSP Elapsed Cycles        cycle   850,817,312\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.19\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,315,803\n",
            "    Memory Throughput                 %        70.88\n",
            "    DRAM Throughput                   %        70.88\n",
            "    Duration                         ms         9.09\n",
            "    L1/TEX Cache Throughput           %        67.68\n",
            "    L2 Cache Throughput               %        23.92\n",
            "    SM Active Cycles              cycle 5,360,900.62\n",
            "    Compute (SM) Throughput           %        30.20\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.37\n",
            "    Achieved Active Warps Per SM           warp        30.20\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,413,944\n",
            "    Total DRAM Elapsed Cycles        cycle  377,126,912\n",
            "    Average L1 Active Cycles         cycle 5,360,900.62\n",
            "    Total L1 Elapsed Cycles          cycle  215,883,336\n",
            "    Average L2 Active Cycles         cycle 7,789,533.38\n",
            "    Total L2 Elapsed Cycles          cycle  248,610,272\n",
            "    Average SM Active Cycles         cycle 5,360,900.62\n",
            "    Total SM Elapsed Cycles          cycle  215,883,336\n",
            "    Average SMSP Active Cycles       cycle 5,358,023.82\n",
            "    Total SMSP Elapsed Cycles        cycle  863,533,344\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.92\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,424,406\n",
            "    Memory Throughput                 %        74.27\n",
            "    DRAM Throughput                   %        74.27\n",
            "    Duration                         ms         9.27\n",
            "    L1/TEX Cache Throughput           %        68.46\n",
            "    L2 Cache Throughput               %        23.39\n",
            "    SM Active Cycles              cycle 5,330,979.10\n",
            "    Compute (SM) Throughput           %        30.58\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        96.89\n",
            "    Achieved Active Warps Per SM           warp        31.00\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,888,641\n",
            "    Total DRAM Elapsed Cycles        cycle  365,047,808\n",
            "    Average L1 Active Cycles         cycle 5,330,979.10\n",
            "    Total L1 Elapsed Cycles          cycle  213,160,336\n",
            "    Average L2 Active Cycles         cycle 7,760,694.78\n",
            "    Total L2 Elapsed Cycles          cycle  253,690,336\n",
            "    Average SM Active Cycles         cycle 5,330,979.10\n",
            "    Total SM Elapsed Cycles          cycle  213,160,336\n",
            "    Average SMSP Active Cycles       cycle 5,255,699.34\n",
            "    Total SMSP Elapsed Cycles        cycle  852,641,344\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.04\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,335,472\n",
            "    Memory Throughput                 %        72.71\n",
            "    DRAM Throughput                   %        72.71\n",
            "    Duration                         ms         9.12\n",
            "    L1/TEX Cache Throughput           %        67.87\n",
            "    L2 Cache Throughput               %        23.94\n",
            "    SM Active Cycles              cycle 5,295,397.22\n",
            "    Compute (SM) Throughput           %        30.31\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.96\n",
            "    Achieved Active Warps Per SM           warp        30.71\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,402,886\n",
            "    Total DRAM Elapsed Cycles        cycle  367,497,216\n",
            "    Average L1 Active Cycles         cycle 5,295,397.22\n",
            "    Total L1 Elapsed Cycles          cycle  215,052,456\n",
            "    Average L2 Active Cycles         cycle 7,881,570.88\n",
            "    Total L2 Elapsed Cycles          cycle  249,530,720\n",
            "    Average SM Active Cycles         cycle 5,295,397.22\n",
            "    Total SM Elapsed Cycles          cycle  215,052,456\n",
            "    Average SMSP Active Cycles       cycle 5,299,798.64\n",
            "    Total SMSP Elapsed Cycles        cycle  860,209,824\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.10\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,301,575\n",
            "    Memory Throughput                 %        71.63\n",
            "    DRAM Throughput                   %        71.63\n",
            "    Duration                         ms         9.06\n",
            "    L1/TEX Cache Throughput           %        68.04\n",
            "    L2 Cache Throughput               %        24.01\n",
            "    SM Active Cycles              cycle 5,323,536.55\n",
            "    Compute (SM) Throughput           %        30.39\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        94.45\n",
            "    Achieved Active Warps Per SM           warp        30.22\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,099,567\n",
            "    Total DRAM Elapsed Cycles        cycle  369,647,616\n",
            "    Average L1 Active Cycles         cycle 5,323,536.55\n",
            "    Total L1 Elapsed Cycles          cycle  214,471,688\n",
            "    Average L2 Active Cycles         cycle 7,826,541.03\n",
            "    Total L2 Elapsed Cycles          cycle  247,945,344\n",
            "    Average SM Active Cycles         cycle 5,323,536.55\n",
            "    Total SM Elapsed Cycles          cycle  214,471,688\n",
            "    Average SMSP Active Cycles       cycle 5,305,288.96\n",
            "    Total SMSP Elapsed Cycles        cycle  857,886,752\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,342,255\n",
            "    Memory Throughput                 %        73.44\n",
            "    DRAM Throughput                   %        73.44\n",
            "    Duration                         ms         9.13\n",
            "    L1/TEX Cache Throughput           %        68.70\n",
            "    L2 Cache Throughput               %        23.74\n",
            "    SM Active Cycles              cycle 5,338,314.95\n",
            "    Compute (SM) Throughput           %        30.70\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.21\n",
            "    Achieved Active Warps Per SM           warp        30.47\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle 33,458,727.50\n",
            "    Total DRAM Elapsed Cycles        cycle   364,474,368\n",
            "    Average L1 Active Cycles         cycle  5,338,314.95\n",
            "    Total L1 Elapsed Cycles          cycle   212,362,352\n",
            "    Average L2 Active Cycles         cycle  7,871,508.94\n",
            "    Total L2 Elapsed Cycles          cycle   249,847,904\n",
            "    Average SM Active Cycles         cycle  5,338,314.95\n",
            "    Total SM Elapsed Cycles          cycle   212,362,352\n",
            "    Average SMSP Active Cycles       cycle  5,346,927.18\n",
            "    Total SMSP Elapsed Cycles        cycle   849,449,408\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.01\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,337,804\n",
            "    Memory Throughput                 %        73.02\n",
            "    DRAM Throughput                   %        73.02\n",
            "    Duration                         ms         9.12\n",
            "    L1/TEX Cache Throughput           %        68.78\n",
            "    L2 Cache Throughput               %        23.81\n",
            "    SM Active Cycles              cycle 5,338,235.65\n",
            "    Compute (SM) Throughput           %        30.71\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.31\n",
            "    Achieved Active Warps Per SM           warp        30.50\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,359,329\n",
            "    Total DRAM Elapsed Cycles        cycle  365,461,504\n",
            "    Average L1 Active Cycles         cycle 5,338,235.65\n",
            "    Total L1 Elapsed Cycles          cycle  212,247,648\n",
            "    Average L2 Active Cycles         cycle 7,693,351.72\n",
            "    Total L2 Elapsed Cycles          cycle  249,639,616\n",
            "    Average SM Active Cycles         cycle 5,338,235.65\n",
            "    Total SM Elapsed Cycles          cycle  212,247,648\n",
            "    Average SMSP Active Cycles       cycle 5,309,506.84\n",
            "    Total SMSP Elapsed Cycles        cycle  848,990,592\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 32, 1)x(16, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         5.05\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle    5,366,069\n",
            "    Memory Throughput                 %        72.88\n",
            "    DRAM Throughput                   %        72.88\n",
            "    Duration                         ms         9.17\n",
            "    L1/TEX Cache Throughput           %        68.30\n",
            "    L2 Cache Throughput               %        23.62\n",
            "    SM Active Cycles              cycle 5,363,168.03\n",
            "    Compute (SM) Throughput           %        30.46\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread         262,144\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                                6.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            4\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        95.11\n",
            "    Achieved Active Warps Per SM           warp        30.44\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- ------------\n",
            "    Metric Name                Metric Unit Metric Value\n",
            "    -------------------------- ----------- ------------\n",
            "    Average DRAM Active Cycles       cycle   33,760,637\n",
            "    Total DRAM Elapsed Cycles        cycle  370,568,192\n",
            "    Average L1 Active Cycles         cycle 5,363,168.03\n",
            "    Total L1 Elapsed Cycles          cycle  214,011,568\n",
            "    Average L2 Active Cycles         cycle 7,861,906.03\n",
            "    Total L2 Elapsed Cycles          cycle  250,961,376\n",
            "    Average SM Active Cycles         cycle 5,363,168.03\n",
            "    Total SM Elapsed Cycles          cycle  214,011,568\n",
            "    Average SMSP Active Cycles       cycle 5,330,438.28\n",
            "    Total SMSP Elapsed Cycles        cycle  856,046,272\n",
            "    -------------------------- ----------- ------------\n",
            "\n",
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 2874 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 1059.6 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%\n",
            "==WARNING== Backing up device memory in system memory. Kernel replay might be slow. Consider using \"--replay-mode application\" to avoid memory save-and-restore.\n",
            "....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 1: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 2: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 3: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 4: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 5: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 6: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 7: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 8: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 9: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 10: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 11: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 12: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 13: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 14: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 15: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 16: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 17: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 18: 0%....50%....100% - 9 passes\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 19: 0%....50%....100% - 9 passes\n",
            "20x GPU_laplace3d_new: 85255.8 (ms) \n",
            "\n",
            "Copy u2 to host: 3601.4 (ms) \n",
            "\n",
            "==PROF== Disconnected from process 2874\n",
            "[2874] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,003,416\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,991,451.85\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.83\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.17%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,501,491\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,584,640\n",
            "    Average L1 Active Cycles         cycle 31,991,451.85\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,760,840\n",
            "    Average L2 Active Cycles         cycle 46,732,536.22\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,769,632\n",
            "    Average SM Active Cycles         cycle 31,991,451.85\n",
            "    Total SM Elapsed Cycles          cycle 1,279,760,840\n",
            "    Average SMSP Active Cycles       cycle 31,989,154.29\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,043,360\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,012,638\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,994,916.25\n",
            "    Compute (SM) Throughput           %         58.34\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 199,518,622.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,186,006,528\n",
            "    Average L1 Active Cycles         cycle  31,994,916.25\n",
            "    Total L1 Elapsed Cycles          cycle  1,279,838,600\n",
            "    Average L2 Active Cycles         cycle  46,743,816.72\n",
            "    Total L2 Elapsed Cycles          cycle  1,497,200,288\n",
            "    Average SM Active Cycles         cycle  31,994,916.25\n",
            "    Total SM Elapsed Cycles          cycle  1,279,838,600\n",
            "    Average SMSP Active Cycles       cycle  31,995,173.58\n",
            "    Total SMSP Elapsed Cycles        cycle  5,119,354,400\n",
            "    -------------------------- ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,008,269\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.87\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,986,422.48\n",
            "    Compute (SM) Throughput           %         58.36\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.86\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.14%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 199,513,605.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,185,437,184\n",
            "    Average L1 Active Cycles         cycle  31,986,422.48\n",
            "    Total L1 Elapsed Cycles          cycle  1,279,594,520\n",
            "    Average L2 Active Cycles         cycle  46,737,896.09\n",
            "    Total L2 Elapsed Cycles          cycle  1,497,001,280\n",
            "    Average SM Active Cycles         cycle  31,986,422.48\n",
            "    Total SM Elapsed Cycles          cycle  1,279,594,520\n",
            "    Average SMSP Active Cycles       cycle  31,989,167.79\n",
            "    Total SMSP Elapsed Cycles        cycle  5,118,378,080\n",
            "    -------------------------- ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,011,627\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,991,504.88\n",
            "    Compute (SM) Throughput           %         58.34\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.86\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.14%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,518,170\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,924,608\n",
            "    Average L1 Active Cycles         cycle 31,991,504.88\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,830,088\n",
            "    Average L2 Active Cycles         cycle 46,741,942.28\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,158,432\n",
            "    Average SM Active Cycles         cycle 31,991,504.88\n",
            "    Total SM Elapsed Cycles          cycle 1,279,830,088\n",
            "    Average SMSP Active Cycles       cycle 31,993,447.71\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,320,352\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,004,858\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,989,997.30\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.84\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.16%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,508,763\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,809,920\n",
            "    Average L1 Active Cycles         cycle 31,989,997.30\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,666,048\n",
            "    Average L2 Active Cycles         cycle 46,732,267.09\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,841,920\n",
            "    Average SM Active Cycles         cycle 31,989,997.30\n",
            "    Total SM Elapsed Cycles          cycle 1,279,666,048\n",
            "    Average SMSP Active Cycles       cycle 31,989,282.75\n",
            "    Total SMSP Elapsed Cycles        cycle 5,118,664,192\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,012,208\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,994,640.52\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 199,513,862.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,185,891,840\n",
            "    Average L1 Active Cycles         cycle  31,994,640.52\n",
            "    Total L1 Elapsed Cycles          cycle  1,279,790,960\n",
            "    Average L2 Active Cycles         cycle  46,743,692.69\n",
            "    Total L2 Elapsed Cycles          cycle  1,497,185,440\n",
            "    Average SM Active Cycles         cycle  31,994,640.52\n",
            "    Total SM Elapsed Cycles          cycle  1,279,790,960\n",
            "    Average SMSP Active Cycles       cycle  31,996,968.41\n",
            "    Total SMSP Elapsed Cycles        cycle  5,119,163,840\n",
            "    -------------------------- ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,003,514\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.87\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,985,994.90\n",
            "    Compute (SM) Throughput           %         58.36\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.84\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.16%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,504,627\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,572,352\n",
            "    Average L1 Active Cycles         cycle 31,985,994.90\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,578,728\n",
            "    Average L2 Active Cycles         cycle 46,732,512.06\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,778,816\n",
            "    Average SM Active Cycles         cycle 31,985,994.90\n",
            "    Total SM Elapsed Cycles          cycle 1,279,578,728\n",
            "    Average SMSP Active Cycles       cycle 31,992,196.70\n",
            "    Total SMSP Elapsed Cycles        cycle 5,118,314,912\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,012,146\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,994,481.73\n",
            "    Compute (SM) Throughput           %         58.34\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,514,303\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,871,360\n",
            "    Average L1 Active Cycles         cycle 31,994,481.73\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,887,984\n",
            "    Average L2 Active Cycles         cycle 46,743,192.06\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,182,432\n",
            "    Average SM Active Cycles         cycle 31,994,481.73\n",
            "    Total SM Elapsed Cycles          cycle 1,279,887,984\n",
            "    Average SMSP Active Cycles       cycle 31,993,619.48\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,551,936\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,002,745\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,990,951.93\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.83\n",
            "    Achieved Active Warps Per SM           warp        26.50\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.17%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,507,136\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,486,336\n",
            "    Average L1 Active Cycles         cycle 31,990,951.93\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,725,328\n",
            "    Average L2 Active Cycles         cycle 46,734,676.62\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,742,816\n",
            "    Average SM Active Cycles         cycle 31,990,951.93\n",
            "    Total SM Elapsed Cycles          cycle 1,279,725,328\n",
            "    Average SMSP Active Cycles       cycle 31,991,679.85\n",
            "    Total SMSP Elapsed Cycles        cycle 5,118,901,312\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,015,419\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.73\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,995,325.55\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,523,153\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,937,920\n",
            "    Average L1 Active Cycles         cycle 31,995,325.55\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,751,384\n",
            "    Average L2 Active Cycles         cycle 46,740,039.97\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,335,648\n",
            "    Average SM Active Cycles         cycle 31,995,325.55\n",
            "    Total SM Elapsed Cycles          cycle 1,279,751,384\n",
            "    Average SMSP Active Cycles       cycle 31,993,110.14\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,005,536\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,003,849\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.87\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,990,251.82\n",
            "    Compute (SM) Throughput           %         58.36\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.83\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.17%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,507,145\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,469,952\n",
            "    Average L1 Active Cycles         cycle 31,990,251.82\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,474,872\n",
            "    Average L2 Active Cycles         cycle 46,736,715.94\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,794,624\n",
            "    Average SM Active Cycles         cycle 31,990,251.82\n",
            "    Total SM Elapsed Cycles          cycle 1,279,474,872\n",
            "    Average SMSP Active Cycles       cycle 31,986,176.31\n",
            "    Total SMSP Elapsed Cycles        cycle 5,117,899,488\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,013,635\n",
            "    Memory Throughput                 %         73.01\n",
            "    DRAM Throughput                   %         73.01\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,995,117.18\n",
            "    Compute (SM) Throughput           %         58.34\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,515,043\n",
            "    Total DRAM Elapsed Cycles        cycle 2,186,039,296\n",
            "    Average L1 Active Cycles         cycle 31,995,117.18\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,886,016\n",
            "    Average L2 Active Cycles         cycle 46,736,599.09\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,252,096\n",
            "    Average SM Active Cycles         cycle 31,995,117.18\n",
            "    Total SM Elapsed Cycles          cycle 1,279,886,016\n",
            "    Average SMSP Active Cycles       cycle 31,995,491.62\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,544,064\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- ------------\n",
            "    Metric Name             Metric Unit Metric Value\n",
            "    ----------------------- ----------- ------------\n",
            "    DRAM Frequency                  Ghz         4.99\n",
            "    SM Frequency                    Mhz       585.00\n",
            "    Elapsed Cycles                cycle   32,006,593\n",
            "    Memory Throughput                 %        73.03\n",
            "    DRAM Throughput                   %        73.03\n",
            "    Duration                         ms        54.71\n",
            "    L1/TEX Cache Throughput           %        61.86\n",
            "    L2 Cache Throughput               %        35.39\n",
            "    SM Active Cycles              cycle   31,989,540\n",
            "    Compute (SM) Throughput           %        58.35\n",
            "    ----------------------- ----------- ------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.84\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.16%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,505,533\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,449,472\n",
            "    Average L1 Active Cycles         cycle    31,989,540\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,673,520\n",
            "    Average L2 Active Cycles         cycle    46,733,924\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,923,008\n",
            "    Average SM Active Cycles         cycle    31,989,540\n",
            "    Total SM Elapsed Cycles          cycle 1,279,673,520\n",
            "    Average SMSP Active Cycles       cycle 31,990,409.76\n",
            "    Total SMSP Elapsed Cycles        cycle 5,118,694,080\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,013,639\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.72\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,995,210.02\n",
            "    Compute (SM) Throughput           %         58.34\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,511,051\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,797,632\n",
            "    Average L1 Active Cycles         cycle 31,995,210.02\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,857,768\n",
            "    Average L2 Active Cycles         cycle 46,744,405.19\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,252,256\n",
            "    Average SM Active Cycles         cycle 31,995,210.02\n",
            "    Total SM Elapsed Cycles          cycle 1,279,857,768\n",
            "    Average SMSP Active Cycles       cycle 31,996,902.06\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,431,072\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,004,798\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,986,943.07\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.84\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.16%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,502,295\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,441,280\n",
            "    Average L1 Active Cycles         cycle 31,986,943.07\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,688,776\n",
            "    Average L2 Active Cycles         cycle 46,734,528.22\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,838,688\n",
            "    Average SM Active Cycles         cycle 31,986,943.07\n",
            "    Total SM Elapsed Cycles          cycle 1,279,688,776\n",
            "    Average SMSP Active Cycles       cycle 31,986,412.05\n",
            "    Total SMSP Elapsed Cycles        cycle 5,118,755,104\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,015,824\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.73\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,997,209.73\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,511,628\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,977,856\n",
            "    Average L1 Active Cycles         cycle 31,997,209.73\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,754,136\n",
            "    Average L2 Active Cycles         cycle 46,739,312.94\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,354,624\n",
            "    Average SM Active Cycles         cycle 31,997,209.73\n",
            "    Total SM Elapsed Cycles          cycle 1,279,754,136\n",
            "    Average SMSP Active Cycles       cycle 31,994,534.05\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,016,544\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,005,631\n",
            "    Memory Throughput                 %         73.03\n",
            "    DRAM Throughput                   %         73.03\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.87\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,986,757.02\n",
            "    Compute (SM) Throughput           %         58.36\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.85\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.15%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,508,361\n",
            "    Total DRAM Elapsed Cycles        cycle 2,185,494,528\n",
            "    Average L1 Active Cycles         cycle 31,986,757.02\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,411,856\n",
            "    Average L2 Active Cycles         cycle 46,736,521.81\n",
            "    Total L2 Elapsed Cycles          cycle 1,496,877,728\n",
            "    Average SM Active Cycles         cycle 31,986,757.02\n",
            "    Total SM Elapsed Cycles          cycle 1,279,411,856\n",
            "    Average SMSP Active Cycles       cycle 31,988,890.36\n",
            "    Total SMSP Elapsed Cycles        cycle 5,117,647,424\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,015,981\n",
            "    Memory Throughput                 %         73.01\n",
            "    DRAM Throughput                   %         73.01\n",
            "    Duration                         ms         54.73\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,994,446.73\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.86\n",
            "    Achieved Active Warps Per SM           warp        26.52\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.14%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   199,516,029\n",
            "    Total DRAM Elapsed Cycles        cycle 2,186,055,680\n",
            "    Average L1 Active Cycles         cycle 31,994,446.73\n",
            "    Total L1 Elapsed Cycles          cycle 1,279,804,768\n",
            "    Average L2 Active Cycles         cycle 46,746,231.94\n",
            "    Total L2 Elapsed Cycles          cycle 1,497,355,040\n",
            "    Average SM Active Cycles         cycle 31,994,446.73\n",
            "    Total SM Elapsed Cycles          cycle 1,279,804,768\n",
            "    Average SMSP Active Cycles       cycle 31,995,551.62\n",
            "    Total SMSP Elapsed Cycles        cycle 5,119,219,072\n",
            "    -------------------------- ----------- -------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,007,348\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.71\n",
            "    L1/TEX Cache Throughput           %         61.86\n",
            "    L2 Cache Throughput               %         35.39\n",
            "    SM Active Cycles              cycle 31,994,678.52\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.83\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.17%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.8%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 199,508,725.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,185,674,752\n",
            "    Average L1 Active Cycles         cycle  31,994,678.52\n",
            "    Total L1 Elapsed Cycles          cycle  1,279,609,104\n",
            "    Average L2 Active Cycles         cycle  46,734,716.12\n",
            "    Total L2 Elapsed Cycles          cycle  1,496,952,160\n",
            "    Average SM Active Cycles         cycle  31,994,678.52\n",
            "    Total SM Elapsed Cycles          cycle  1,279,609,104\n",
            "    Average SMSP Active Cycles       cycle  31,991,269.12\n",
            "    Total SMSP Elapsed Cycles        cycle  5,118,436,416\n",
            "    -------------------------- ----------- --------------\n",
            "\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 256)x(32, 2, 4), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    32,016,170\n",
            "    Memory Throughput                 %         73.02\n",
            "    DRAM Throughput                   %         73.02\n",
            "    Duration                         ms         54.73\n",
            "    L1/TEX Cache Throughput           %         61.85\n",
            "    L2 Cache Throughput               %         35.38\n",
            "    SM Active Cycles              cycle 31,995,654.88\n",
            "    Compute (SM) Throughput           %         58.35\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   256\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              4,194,304\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block           10\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            4\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        82.86\n",
            "    Achieved Active Warps Per SM           warp        26.51\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 17.14%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (82.9%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 199,519,120.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,185,904,128\n",
            "    Average L1 Active Cycles         cycle  31,995,654.88\n",
            "    Total L1 Elapsed Cycles          cycle  1,279,820,976\n",
            "    Average L2 Active Cycles         cycle  46,743,410.19\n",
            "    Total L2 Elapsed Cycles          cycle  1,497,365,248\n",
            "    Average SM Active Cycles         cycle  31,995,654.88\n",
            "    Total SM Elapsed Cycles          cycle  1,279,820,976\n",
            "    Average SMSP Active Cycles       cycle  31,997,808.38\n",
            "    Total SMSP Elapsed Cycles        cycle  5,119,283,904\n",
            "    -------------------------- ----------- --------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#(9)"
      ],
      "metadata": {
        "id": "2goPOL-mJ35_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* To calculate the bandwidth, we first find the total size of the points.\n",
        "* For `Nx=1024, Ny=1024, Nz=1024`, the total size is : $$ TotalSize = Nx×Ny×Nz = 1024^{3} = 1073741824 float $$\n",
        "\n",
        " $$ TotalSize_{GB} = 4 × 1073741824 / 2^{30} = 4 GB$$\n",
        "\n",
        "* The Kernel has two types of points, *Exterior* and *Interior* points:\n",
        "    * *Exterior points* : Exterior Points:\n",
        "These are the points on the boundary of the grid that do not have all six neighbors. They are simply read from u1 and written to u2. To estimate their number, consider the six faces of the 3D grid:\n",
        " $I =6×10242=6×1,048,576=6,291,456$ points The memory size occupied by these points is: $I_{GB} = 1024^{2} × 6 floats = 6 × 4 × 1024^{2}/(1024^{3}) GB = 0.023 GB$  \n",
        "    * *Interior points*:These are the points that have all six neighbors and will involve accessing additional data for computing the average. Their number is: $E = 1,073,741,824 - 6,291,456 = 1,067,450,368$ points And the corresponding memory size is:\n",
        " $$E_{GB}=4GB−0.023 GB≈3.977$$\n",
        "\n",
        "##Estimating the Bandwidth:\n",
        "* We can have two assumptions, *optimistic* and *passimistic* for estimating the Bandwidth.\n",
        "    1. **Optimisitc assumption**, We consider an optimistic assumption where caching is efficient enough that each point (whether interior or exterior) is loaded with a single read and written with a single write. That is, each data point undergoes: 1 read+1 write1 read+1 write:\n",
        "        * **Total Data Transfer per Iteration:**\n",
        "        * The entire grid of 4 GB is read and then written\n",
        "    $$TotalData = 2 * 4 = 8 GB$$,\n",
        "        * **Ecxusion Time Per Iteration**\n",
        "        $$ExecutionTime_i = 899 / 20 = 44.95 (ms)$$\n",
        "        * **Effective Bandwidth Calculation:**\n",
        "        $$B=10^{3} × 8GB/44.95 (s)​≈177.9GB/s$$\n",
        "        * **Efficiency of Bandwidth:**\n",
        "        $$\\eta = \\frac{177.9}{300} = 0.593$$\n",
        "    2. **Pessimistic Assumption**, In this scenario, we assume that when calculating the averages for the interior data points, each interior point requires 7 loads from the source array (d_u1) and 1 store to the destination array (d_u2). For exterior points, we assume that each point requires 1 load from d_u1 and 1 store to d_u2.\n",
        "\n",
        "      * **Exterior Points:**\n",
        "  since the number of exterior points in this case is small, we will ignore it.\n",
        "      * **Interior Points:**\n",
        "  Each interior point in the u2 array requires:\n",
        "          7 loads from d_u1\n",
        "          1 store to d_u2\n",
        "          Total: 8 memory accesses per point\n",
        "    Number of interior points: $1,067,450,368$\n",
        "    Each interior point transfers: $$8 × 4 bytes = 32 bytes$$\n",
        "    \n",
        "      * **Total memory transferred for interior points:**\n",
        "    $$32 bytes × 1,067,450,368 ≈ 31.8 GB$$\n",
        "\n",
        "      * **Overall Data Transfer and Bandwidth Estimation:**\n",
        "\n",
        "      Total memory transferred per iteration is approximately$$:≈ 32 GB$$\n",
        "      * **Effective Bandwidth Calculation:**\n",
        "      Given an execution time of 44.95 ms per iteration, the estimated effective bandwidth is:\n",
        "      $$32 GB / 0.04495 s ≈ 711.9 GB/s$$\n",
        "      * **Efficiency of Bandwidth:**\n",
        "        $$\\eta = \\frac{711.9}{300} = 2.373$$\n",
        "\n",
        "    * **Note:**\n",
        "    `-This is more than the T4 capability of bandwidth - 300GB/s.\n",
        "    The explaanation for this is that most of the reads operations are overlapped and read directly from the cache not from the device memory.`\n",
        "    `-The time used here from the best Block Combination (32, 2, 4) over the number of iterations 20.`"
      ],
      "metadata": {
        "id": "VSv3ZCNbJ7mE"
      }
    }
  ]
}