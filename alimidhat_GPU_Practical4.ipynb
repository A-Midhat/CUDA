{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "8gZA4THHYkoN",
        "3RmcnYfw6XD1",
        "8yEliwI6Yb3W",
        "Ynr1qJf6bVR5",
        "66V1P0Mh6m65"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Midhat/CUDA/blob/main/alimidhat_GPU_Practical4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Ali Midhat Abdelgadir Abdalla**"
      ],
      "metadata": {
        "id": "geQR-Bw0BY2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs**\n",
        "\n",
        "# **Practical 4**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify the details of the GPU which is available to you, and upload the usual two header files."
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "08875df3-8801-47e3-a125-b0afccfdbb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun  8 06:57:19 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "4c7f7aa2-926f-4c6b-ef08-421f4958f700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-17 16:52:29--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-17 16:52:30 (200 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2025-02-17 16:52:30--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:202::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-02-17 16:52:31 (366 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file reduction.cu which includes within it a reference C++ routine against which the CUDA results are compared."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (4)"
      ],
      "metadata": {
        "id": "8gZA4THHYkoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Practical 4 -- initial code for shared memory reduction for\n",
        "//                a single block which is a power of two in size\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <float.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "float reduction_gold(float* idata, int len)\n",
        "{\n",
        "  float sum = 0.0f;\n",
        "  for(int i=0; i<len; i++) sum += idata[i];\n",
        "  printf(\"\\nCPU Result %f \", sum);\n",
        "  return sum;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "// g_odata is output (final reduction result)\n",
        "// g_idata is input\n",
        "\n",
        "__global__ void reduction(float *g_odata, float *g_idata)\n",
        "{\n",
        "    // dynamically allocated shared memory\n",
        "\n",
        "    extern  __shared__  float temp[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    // first, each thread loads data into shared memory\n",
        "\n",
        "    temp[tid] = g_idata[tid];\n",
        "\n",
        "    // next, we perform binary tree reduction\n",
        "\n",
        "    for (int d=blockDim.x/2; d>0; d=d/2) {\n",
        "      __syncthreads();  // ensure previous step completed\n",
        "      if (tid<d)  temp[tid] += temp[tid+d];\n",
        "    }\n",
        "\n",
        "    // finally, first thread puts result into global memory\n",
        "\n",
        "    if (tid==0) {\n",
        "      g_odata[0] = temp[0];\n",
        "      printf(\"\\nGPU Reduction Result %f \", temp[0]);\n",
        "      }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main( int argc, const char** argv)\n",
        "{\n",
        "  int num_blocks, num_threads, num_elements, mem_size, shared_mem_size;\n",
        "\n",
        "  float *h_data, *d_idata, *d_odata;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  num_blocks   = 1;  // start with only 1 thread block\n",
        "  num_threads  = 512;\n",
        "  num_elements = num_blocks*num_threads;\n",
        "  mem_size     = sizeof(float) * num_elements;\n",
        "\n",
        "  // allocate host memory to store the input data\n",
        "  // and initialize to integer values between 0 and 10\n",
        "\n",
        "  h_data = (float*) malloc(mem_size);\n",
        "\n",
        "  for(int i = 0; i < num_elements; i++)\n",
        "    h_data[i] = floorf(10.0f*(rand()/(float)RAND_MAX));\n",
        "\n",
        "  // compute reference solution\n",
        "\n",
        "  float sum = reduction_gold(h_data, num_elements);\n",
        "\n",
        "  // allocate device memory input and output arrays\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_idata, mem_size) );\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_odata, sizeof(float)) );\n",
        "\n",
        "  // copy host memory to device input array\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_idata, h_data, mem_size,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // execute the kernel\n",
        "\n",
        "  shared_mem_size = sizeof(float) * num_threads;\n",
        "  reduction<<<num_blocks,num_threads,shared_mem_size>>>(d_odata,d_idata);\n",
        "  getLastCudaError(\"reduction kernel execution failed\");\n",
        "\n",
        "  // copy result from device to host\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_data, d_odata, sizeof(float),\n",
        "                              cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // check results\n",
        "\n",
        "  printf(\"\\nReduction error = %f\\n\",h_data[0]-sum);\n",
        "\n",
        "  // cleanup memory\n",
        "\n",
        "  free(h_data);\n",
        "  checkCudaErrors( cudaFree(d_idata) );\n",
        "  checkCudaErrors( cudaFree(d_odata) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "96b91abf-1c73-4fb8-b7fa-b3336499a5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.  Note that the compilation links in the CUDA random number generation library cuRAND.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "3ce41d80-0a4c-49ca-95ae-5e4b96f94271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 26 bytes gmem, 16 bytes cmem[4]\n",
            "ptxas info    : Compiling entry function '_Z9reductionPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z9reductionPfS_\n",
            "    8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 24 registers, 8 bytes cumulative stack size, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "6b988cb9-2ba4-4cbe-d216-944f689ad610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "Gold Reduction Result 2351.000000 \n",
            "GPU Reduction Result 2351.000000 \n",
            "reduction error = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1. CPU Reference Sum\n",
        "The CPU computes the expected sum using normal sequential summation.\n",
        "\n",
        "### 2. GPU Parallel Reduction\n",
        "The CUDA kernel:\n",
        "- Loads data into shared memory.\n",
        "- Performs parallel reduction using a binary tree approach.\n",
        "- returns only a single value which holds the sum value.\n",
        "\n",
        "### 3. Verification\n",
        "- At the main function we compare both results, `reduction_gold` and `reduction` and see if there is some error difference between the two, if not (as we can see), it means our GPU reduction is working.\n",
        "---"
      ],
      "metadata": {
        "id": "-DOB4HpHl-Hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (5)"
      ],
      "metadata": {
        "id": "3RmcnYfw6XD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Practical 4 -- initial code for shared memory reduction for\n",
        "//                a single block which is a power of two in size\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <float.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "float reduction_gold(float* idata, int len)\n",
        "{\n",
        "  float sum = 0.0f;\n",
        "  for(int i=0; i<len; i++) sum += idata[i];\n",
        "  printf(\"\\nCPU Result %f \", sum);\n",
        "  return sum;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "// g_odata is output (final reduction result)\n",
        "// g_idata is input\n",
        "\n",
        "__global__ void reduction(float *g_odata, float *g_idata)\n",
        "{\n",
        "    // dynamically allocated shared memory\n",
        "\n",
        "    extern  __shared__  float temp[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    // number of threads per block\n",
        "    int num_threads = blockDim.x;\n",
        "\n",
        "    int m1; // Nearest power of 2 more than num_threads\n",
        "    for (m1=1; m1<num_threads; m1=2*m1) {};\n",
        "    // shift it left by 1 to get the next power of 2\n",
        "    m1 = m1/2;\n",
        "\n",
        "    // remainings threads\n",
        "    int diff = num_threads - m1;\n",
        "\n",
        "    // first, each thread loads data into shared memory\n",
        "\n",
        "    temp[tid] = g_idata[tid];\n",
        "\n",
        "    // add the remaining threads only\n",
        "    // and make temp with the size of multiple of power of 2\n",
        "    if (tid < diff){\n",
        "      temp[tid] += g_idata[tid + m1];\n",
        "    }\n",
        "\n",
        "\n",
        "    // next, we perform binary tree reduction\n",
        "\n",
        "    for (int d=m1/2; d>0; d=d/2) {\n",
        "      __syncthreads();  // ensure previous step completed\n",
        "      if (tid<d)  temp[tid] += temp[tid+d];\n",
        "    }\n",
        "\n",
        "    // finally, first thread puts result into global memory\n",
        "\n",
        "    if (tid==0) {\n",
        "      g_odata[0] = temp[0];\n",
        "      printf(\"\\nGPU Result %f \", temp[0]);\n",
        "      }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main( int argc, const char** argv)\n",
        "{\n",
        "  int num_blocks, num_threads, num_elements, mem_size, shared_mem_size;\n",
        "\n",
        "  float *h_data, *d_idata, *d_odata;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  num_blocks   = 1;  // start with only 1 thread block\n",
        "  num_threads  = 192; // Not a multiple of a power of 2 number\n",
        "  num_elements = num_blocks*num_threads;\n",
        "  mem_size     = sizeof(float) * num_elements;\n",
        "\n",
        "  // allocate host memory to store the input data\n",
        "  // and initialize to integer values between 0 and 10\n",
        "\n",
        "  h_data = (float*) malloc(mem_size);\n",
        "\n",
        "  for(int i = 0; i < num_elements; i++)\n",
        "    h_data[i] = floorf(10.0f*(rand()/(float)RAND_MAX));\n",
        "\n",
        "  // compute reference solution\n",
        "\n",
        "  float sum = reduction_gold(h_data, num_elements);\n",
        "\n",
        "  // allocate device memory input and output arrays\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_idata, mem_size) );\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_odata, sizeof(float)) );\n",
        "\n",
        "  // copy host memory to device input array\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_idata, h_data, mem_size,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // execute the kernel\n",
        "\n",
        "  shared_mem_size = sizeof(float) * num_threads;\n",
        "  reduction<<<num_blocks,num_threads,shared_mem_size>>>(d_odata,d_idata);\n",
        "  getLastCudaError(\"reduction kernel execution failed\");\n",
        "\n",
        "  // copy result from device to host\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(h_data, d_odata, sizeof(float),\n",
        "                              cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // check results\n",
        "\n",
        "  printf(\"\\nCPU/GPU error = %f\\n\",h_data[0]-sum);\n",
        "\n",
        "  // cleanup memory\n",
        "\n",
        "  free(h_data);\n",
        "  checkCudaErrors( cudaFree(d_idata) );\n",
        "  checkCudaErrors( cudaFree(d_odata) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a633b0-32f1-4558-fe15-8484b97b9ec7",
        "id": "tBZelwwVVC7S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d07aa2-67d6-4011-96d0-85f1506f6081",
        "id": "J_i9f1d9VC7V"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 16 bytes gmem, 16 bytes cmem[4]\n",
            "ptxas info    : Compiling entry function '_Z9reductionPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z9reductionPfS_\n",
            "    8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 24 registers, 8 bytes cumulative stack size, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1acfd8a-be68-4b3a-e577-dc0057e89899",
        "id": "NqRDo9odVC7X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "CPU Result 896.000000 \n",
            "GPU Result 896.000000 \n",
            "CPU/GPU error = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "- To enable reduction, we first map the total number of threads to the nearest power of 2.\n",
        "- We iterate, doubling `m1` until it exceeds `num_threads`, then shift it back by dividing by 2, i.e. :\n",
        "  ```cpp\n",
        "  int m1;\n",
        "  for (m1 = 1; m1 < num_threads; m1 *= 2) {}\n",
        "  m1 /= 2;\n",
        "\n",
        "- The difference `(num_threads - m1)` identifies extra threads, which are summed first before proceeding with standard reduction.\n",
        "\n",
        "- Finally, normal reduction algorithm is implement.\n",
        "---"
      ],
      "metadata": {
        "id": "d2SaBQ1w2Si_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (6)"
      ],
      "metadata": {
        "id": "tO6_vhNo6g2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Practical 4 -- initial code for shared memory reduction for\n",
        "//                a single block which is a power of two in size\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <float.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "float reduction_gold(float* idata, int len)\n",
        "{\n",
        "  float sum = 0.0f;\n",
        "  for(int i=0; i<len; i++) sum += idata[i];\n",
        "  printf(\"\\nCPU Result %f \", sum);\n",
        "  return sum;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void reduction(float *g_odata, float *g_idata)\n",
        "{\n",
        "    // dynamically allocated shared memory\n",
        "\n",
        "    extern  __shared__  float temp[];\n",
        "\n",
        "    int tid = threadIdx.x;\n",
        "    // Normal flatten of thereads accross all blocks\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // first, each thread loads data into shared memory\n",
        "\n",
        "    temp[tid] = g_idata[global_id];\n",
        "\n",
        "    // next, we perform binary tree reduction\n",
        "\n",
        "    for (int d=blockDim.x/2; d>0; d=d/2) {\n",
        "      __syncthreads();  // ensure previous step completed\n",
        "      if (tid<d) {\n",
        "     temp[tid] += temp[tid+d];  // Replace this line with:\n",
        "    }\n",
        "    }\n",
        "\n",
        "    // finally, first thread puts result into global memory\n",
        "    if (tid==0) g_odata[blockIdx.x] = temp[0];\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main( int argc, const char** argv)\n",
        "{\n",
        "  int num_blocks, num_threads, num_elements, mem_size, shared_mem_size;\n",
        "\n",
        "  float *h_data, *d_idata, *d_odata;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  num_blocks   = 1000; // multiple blocks\n",
        "  num_threads  = 512;\n",
        "  num_elements = num_blocks*num_threads;\n",
        "  mem_size     = sizeof(float) * num_elements;\n",
        "\n",
        "  // allocate host memory to store the input data\n",
        "  // and initialize to integer values between 0 and 10\n",
        "\n",
        "  h_data = (float*) malloc(mem_size);\n",
        "\n",
        "  for(int i = 0; i < num_elements; i++)\n",
        "    h_data[i] = floorf(10.0f*(rand()/(float)RAND_MAX));\n",
        "\n",
        "  // compute reference solution\n",
        "\n",
        "  float sum = reduction_gold(h_data, num_elements);\n",
        "\n",
        "  // allocate device memory input and output arrays\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_idata, mem_size) );\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_odata, sizeof(float)*num_blocks) ); // changing the size of the output array\n",
        "\n",
        "  // copy host memory to device input array\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_idata, h_data, mem_size,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // execute the kernel\n",
        "\n",
        "  shared_mem_size = sizeof(float) * num_threads;\n",
        "  reduction<<<num_blocks,num_threads,shared_mem_size>>>(d_odata,d_idata);\n",
        "  getLastCudaError(\"reduction kernel execution failed\");\n",
        "\n",
        "  // copy result from device to host\n",
        "  cudaDeviceSynchronize();\n",
        "  checkCudaErrors( cudaMemcpy(h_data, d_odata, sizeof(float)*num_blocks,\n",
        "                              cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // check results\n",
        "  float g_sum = 0.0f;\n",
        "  for (int i=0; i<num_blocks; i++){\n",
        "    g_sum += h_data[i];\n",
        "  }\n",
        "  printf(\"\\nGPU Result %f \", g_sum);\n",
        "  printf(\"\\nError result = %f\\n\",g_sum - sum);\n",
        "\n",
        "  // cleanup memory\n",
        "\n",
        "  free(h_data);\n",
        "  checkCudaErrors( cudaFree(d_idata) );\n",
        "  checkCudaErrors( cudaFree(d_odata) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44615ef-9aeb-4acb-ffb2-071925056f93",
        "id": "yR8XyWoj6lQ6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e788f99-fc82-4305-e3d0-85bd5bb7c7e6",
        "id": "YCs63Hp56lQ7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z9reductionPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z9reductionPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8b0872-0733-4507-c0af-f7e9366e0f6b",
        "id": "zydYzKDQ6lQ8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "CPU Result 2305301.000000 \n",
            "GPU Result 2305301.000000 \n",
            "Error result = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "- Unlike previous implementations using a **single block**, here we scales up by launching multiple blocks (`num_blocks = 1000`). Each block performs an independent reduction on its assigned data chunk.\n",
        "- Then we get sum values of each block.\n",
        "- Finally, we iterate through those values in the host, to get our sum.\n",
        "---"
      ],
      "metadata": {
        "id": "6C5HSZ1X6YVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (7)"
      ],
      "metadata": {
        "id": "8yEliwI6Yb3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Practical 4 -- initial code for shared memory reduction for\n",
        "//                a single block which is a power of two in size\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <float.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "float reduction_gold(float* idata, int len)\n",
        "{\n",
        "  float sum = 0.0f;\n",
        "  for(int i=0; i<len; i++) sum += idata[i];\n",
        "  printf(\"\\nCPU Result %f \", sum);\n",
        "  return sum;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void reduction(float *g_odata, float *g_idata)\n",
        "{\n",
        "    // dynamically allocated shared memory\n",
        "\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int warpIdx = threadIdx.x / 32;\n",
        "    int thread_warp_idx = threadIdx.x % 32;\n",
        "\n",
        "\n",
        "    float sum = g_idata[global_id];\n",
        "\n",
        "    for (int offset = warpSize/2; offset > 0; offset /= 2) {\n",
        "      sum += __shfl_down_sync(0xFFFFFFFF, sum, offset); // shuffle down Built in function\n",
        "    }\n",
        "\n",
        "\n",
        "    if (thread_warp_idx == 0) {\n",
        "        g_odata[warpIdx]= sum;\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main( int argc, const char** argv)\n",
        "{\n",
        "  int num_blocks, num_threads, num_elements, mem_size, shared_mem_size;\n",
        "\n",
        "  float *h_data, *d_idata, *d_odata;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  num_blocks   = 1; // start with only 1 thread block\n",
        "  num_threads  = 512;\n",
        "  num_elements = num_blocks*num_threads;\n",
        "  mem_size     = sizeof(float) * num_elements;\n",
        "\n",
        "  int num_of_warps = ceil((float) num_threads/32) ;\n",
        "\n",
        "  // allocate host memory to store the input data\n",
        "  // and initialize to integer values between 0 and 10\n",
        "\n",
        "  h_data = (float*) malloc(mem_size);\n",
        "\n",
        "  for(int i = 0; i < num_elements; i++)\n",
        "    h_data[i] = floorf(10.0f*(rand()/(float)RAND_MAX));\n",
        "\n",
        "  // compute reference solution\n",
        "\n",
        "  float sum = reduction_gold(h_data, num_elements);\n",
        "\n",
        "  // allocate device memory input and output arrays\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_idata, mem_size) );\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_odata, sizeof(float)*num_of_warps) ); //\n",
        "\n",
        "  // copy host memory to device input array\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_idata, h_data, mem_size,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // execute the kernel\n",
        "\n",
        "  shared_mem_size = sizeof(float) * num_threads;\n",
        "  reduction<<<num_blocks,num_threads,shared_mem_size>>>(d_odata,d_idata);\n",
        "  getLastCudaError(\"reduction kernel execution failed\");\n",
        "\n",
        "  // copy result from device to host\n",
        "  cudaDeviceSynchronize();\n",
        "  checkCudaErrors( cudaMemcpy(h_data, d_odata, sizeof(float)*num_of_warps,\n",
        "                              cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // check results\n",
        "  float g_sum = 0.0f;\n",
        "  for (int i=0; i<num_of_warps; i++){\n",
        "    g_sum += h_data[i];\n",
        "  }\n",
        "  printf(\"\\nGPU result = %f\\n\",g_sum);\n",
        "  printf(\"\\nCPU/GPU error = %f\\n\",g_sum-sum);\n",
        "\n",
        "  // cleanup memory\n",
        "\n",
        "  free(h_data);\n",
        "  checkCudaErrors( cudaFree(d_idata) );\n",
        "  checkCudaErrors( cudaFree(d_odata) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wte2ri6YdQE",
        "outputId": "040d3977-a1ca-46c0-e9c7-6e20f863017b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bd3a0b-0a19-4596-ae56-561974be8904",
        "id": "wxUPWVGH7yLz"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z9reductionPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z9reductionPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e6665a-c5d0-4278-9268-c7863c779a40",
        "id": "FicE0ZGv7yL_"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "CPU Result 2351.000000 \n",
            "GPU result = 2351.000000\n",
            "\n",
            "CPU/GPU error = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "- Instead of reducing across all threads in a block, this approach performs **warp-level reduction** using **CUDA shuffle intrinsics (`__shfl_down_sync`)** for optimized memory efficiency.\n",
        "\n",
        "- **Thread and Warp Indexing**:\n",
        "  - Each thread calculates a **global index**:\n",
        "    ```cpp\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    ```\n",
        "  - Determines **warp index** (`warpIdx`) and **position within the warp** (`thread_warp_idx`):\n",
        "    ```cpp\n",
        "    int warpIdx = threadIdx.x / 32;\n",
        "    int thread_warp_idx = threadIdx.x % 32;\n",
        "    ```\n",
        "\n",
        "  - Threads **shuffle values** within a warp:\n",
        "    ```cpp\n",
        "    sum += __shfl_down_sync(0xFFFFFFFF, sum, offset);\n",
        "    ```\n",
        "  - Each step halves `offset`, reducing values **within the same warp**.\n",
        "\n",
        "  - **Thread 0 of each warp** stores the **partial sum** in global memory:\n",
        "    ```cpp\n",
        "    if (thread_warp_idx == 0) {\n",
        "        g_odata[warpIdx] = sum;\n",
        "    }\n",
        "    ```\n",
        "\n",
        "- **Partial sums** from each warp are copied to the CPU, and then we iterate through it and sum it like e did before.\n",
        "---"
      ],
      "metadata": {
        "id": "bgo7cteL9h9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (7) Extra"
      ],
      "metadata": {
        "id": "Ynr1qJf6bVR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile reduction.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Practical 4 -- initial code for shared memory reduction for\n",
        "//                a single block which is a power of two in size\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <float.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// CPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "float reduction_gold(float* idata, int len)\n",
        "{\n",
        "  float sum = 0.0f;\n",
        "  for(int i=0; i<len; i++) sum += idata[i];\n",
        "  printf(\"\\nCPU Result %f \", sum);\n",
        "  return sum;\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// GPU routine\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void reduction(float *g_odata, float *g_idata)\n",
        "{\n",
        "    // dynamically allocated shared memory\n",
        "\n",
        "    int global_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int warpIdx = global_id / 32;\n",
        "    int thread_warp_idx = threadIdx.x % 32;\n",
        "\n",
        "    float sum = g_idata[global_id];\n",
        "\n",
        "    for (int offset = warpSize/2; offset > 0; offset /= 2) {\n",
        "      sum += __shfl_down_sync(0xFFFFFFFF, sum, offset);\n",
        "    }\n",
        "\n",
        "    // Thread 0 writes the final sum\n",
        "    if (thread_warp_idx == 0) {\n",
        "        g_odata[warpIdx]= sum;\n",
        "    }\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Program main\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main( int argc, const char** argv)\n",
        "{\n",
        "  int num_blocks, num_threads, num_elements, mem_size, shared_mem_size;\n",
        "\n",
        "  float *h_data, *d_idata, *d_odata;\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  num_blocks   = 512;  // multiple Blocks\n",
        "  num_threads  = 512;\n",
        "  num_elements = num_blocks*num_threads;\n",
        "  mem_size     = sizeof(float) * num_elements;\n",
        "\n",
        "  int num_of_warps = ceil((float) num_threads/32) * num_blocks ;\n",
        "\n",
        "  // allocate host memory to store the input data\n",
        "  // and initialize to integer values between 0 and 10\n",
        "\n",
        "  h_data = (float*) malloc(mem_size);\n",
        "\n",
        "  for(int i = 0; i < num_elements; i++)\n",
        "    h_data[i] = floorf(10.0f*(rand()/(float)RAND_MAX));\n",
        "\n",
        "  // compute reference solution\n",
        "\n",
        "  float sum = reduction_gold(h_data, num_elements);\n",
        "\n",
        "  // allocate device memory input and output arrays\n",
        "\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_idata, mem_size) );\n",
        "  checkCudaErrors( cudaMalloc((void**)&d_odata, sizeof(float)*num_of_warps) );\n",
        "\n",
        "  // copy host memory to device input array\n",
        "\n",
        "  checkCudaErrors( cudaMemcpy(d_idata, h_data, mem_size,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "\n",
        "  // execute the kernel\n",
        "\n",
        "  shared_mem_size = sizeof(float) * num_threads;\n",
        "  reduction<<<num_blocks,num_threads,shared_mem_size>>>(d_odata,d_idata);\n",
        "  getLastCudaError(\"reduction kernel execution failed\");\n",
        "\n",
        "  // copy result from device to host\n",
        "  cudaDeviceSynchronize();\n",
        "  checkCudaErrors( cudaMemcpy(h_data, d_odata, sizeof(float)*num_of_warps,\n",
        "                              cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // check results\n",
        "  float g_sum = 0.0f;\n",
        "  for (int i=0; i<num_of_warps; i++){\n",
        "    g_sum += h_data[i];\n",
        "  }\n",
        "\n",
        "  printf(\"\\nGPU result = %f\\n\",g_sum);\n",
        "  printf(\"\\nCPU/GPU error = %f\\n\",g_sum-sum);\n",
        "\n",
        "\n",
        "  // cleanup memory\n",
        "\n",
        "  free(h_data);\n",
        "  checkCudaErrors( cudaFree(d_idata) );\n",
        "  checkCudaErrors( cudaFree(d_odata) );\n",
        "\n",
        "  // CUDA exit -- needed to flush printf write buffer\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a9cc5d-80fc-4c99-dccb-11bfaec3775f",
        "id": "nl1Ci_IdbZvV"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting reduction.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc reduction.cu -o reduction -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6610afe9-d89b-499d-b549-626713130ca4",
        "id": "LbL1MU95bZvh"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z9reductionPfS_' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z9reductionPfS_\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 10 registers, 368 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./reduction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37990284-7b7a-4570-c1c5-9ab1f19bc990",
        "id": "kD3RMWasbZvn"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "\n",
            "CPU Result 1179646.000000 \n",
            "GPU result = 1179646.000000\n",
            "\n",
            "CPU/GPU error = 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "- This implementation extends the **warp-level reduction** (Q.7) approach by introducing **multiple blocks**, improving scalability and performance.\n",
        "\n",
        "- Instead of a **single block**, we now use **multiple blocks** (`num_blocks = 512`).\n",
        "- Each block performs **warp-level reduction**, independently reducing its assigned data.\n",
        "- The final summation is performed on the **CPU** after collecting partial results from all warps across blocks.\n",
        "\n"
      ],
      "metadata": {
        "id": "dRg2qzkQ_KOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra"
      ],
      "metadata": {
        "id": "66V1P0Mh6m65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "tLhEaicpji2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3C521FAvvLCa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}